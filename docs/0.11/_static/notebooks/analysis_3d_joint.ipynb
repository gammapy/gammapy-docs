{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint 3D Analysis\n",
    "In this tutorial we show how to run a joint 3D map-based analysis using three example observations of the Galactic center region with CTA. We start with the required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import DataStore\n",
    "from gammapy.irf import EnergyDispersion, make_psf\n",
    "from gammapy.maps import WcsGeom, MapAxis, Map\n",
    "from gammapy.cube import MapMaker, PSFKernel, MapDataset\n",
    "from gammapy.cube.models import SkyModel, BackgroundModel\n",
    "from gammapy.spectrum.models import PowerLaw\n",
    "from gammapy.image.models import SkyPointSource\n",
    "from gammapy.utils.fitting import Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare modeling input data\n",
    "\n",
    "We first use the `DataStore` object to access the CTA observations and retrieve a list of observations by passing the observations IDs to the `.get_observations()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which data to use and print some information\n",
    "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/cta-1dc/index/gps/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select some observations from these dataset by hand\n",
    "obs_ids = [110380, 111140, 111159]\n",
    "observations = data_store.get_observations(obs_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input maps\n",
    "\n",
    "Now we define a reference geometry for our analysis, We choose a WCS based gemoetry with a binsize of 0.02 deg and also define an energy axis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_axis = MapAxis.from_edges(\n",
    "    np.logspace(-1.0, 1.0, 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0),\n",
    "    binsz=0.02,\n",
    "    width=(10, 8),\n",
    "    coordsys=\"GAL\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[energy_axis],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we define the center coordinate and the FoV offset cut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source position\n",
    "src_pos = SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\")\n",
    "\n",
    "# FoV max\n",
    "offset_max = 4 * u.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps are prepared by calling the `MapMaker.run()` method and passing the `observations`. The `.run()` method returns a Python `dict` containing a `counts`, `background` and `exposure` map. For the joint analysis, we compute the cube per observation and store the result in the `observations_maps` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "observations_data = {}\n",
    "\n",
    "for obs in observations:\n",
    "    # For each observation, the map will be centered on the pointing position.\n",
    "    geom_cutout = geom.cutout(\n",
    "        position=obs.pointing_radec, width=2 * offset_max\n",
    "    )\n",
    "    maker = MapMaker(geom_cutout, offset_max=offset_max)\n",
    "    maps = maker.run([obs])\n",
    "    observations_data[obs.obs_id] = maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare IRFs\n",
    "PSF and Edisp are estimated for each observation at a specific source position defined by `src_pos`:\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define energy grid for edisp\n",
    "energy = energy_axis.edges * energy_axis.unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs in observations:\n",
    "    table_psf = make_psf(obs, src_pos)\n",
    "    psf = PSFKernel.from_table_psf(table_psf, geom, max_radius=\"0.5 deg\")\n",
    "    observations_data[obs.obs_id][\"psf\"] = psf\n",
    "\n",
    "    # create Edisp\n",
    "    offset = src_pos.separation(obs.pointing_radec)\n",
    "    edisp = obs.edisp.to_energy_dispersion(\n",
    "        offset, e_true=energy, e_reco=energy\n",
    "    )\n",
    "    observations_data[obs.obs_id][\"edisp\"] = edisp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save maps as well as IRFs to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs_id in obs_ids:\n",
    "    path = Path(\"analysis_3d_joint\") / \"obs_{}\".format(obs_id)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for key in [\"counts\", \"exposure\", \"background\", \"edisp\", \"psf\"]:\n",
    "        filename = \"{}.fits.gz\".format(key)\n",
    "        observations_data[obs_id][key].write(path / filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood fit\n",
    "\n",
    "### Reading maps and IRFs\n",
    "As first step we define a source model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_model = SkyPointSource(lon_0=\"-0.05 deg\", lat_0=\"-0.05 deg\")\n",
    "spectral_model = PowerLaw(\n",
    "    index=2.4, amplitude=\"2.7e-12 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the maps and IRFs and create the dataset for each observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for obs_id in obs_ids:\n",
    "    path = Path(\"analysis_3d_joint\") / \"obs_{}\".format(obs_id)\n",
    "    \n",
    "    # read counts map and IRFs\n",
    "    counts = Map.read(path / \"counts.fits.gz\")\n",
    "    exposure = Map.read(path / \"exposure.fits.gz\")\n",
    "    \n",
    "    psf = PSFKernel.read(path / \"psf.fits.gz\")\n",
    "    edisp = EnergyDispersion.read(path / \"edisp.fits.gz\")\n",
    "\n",
    "    # create background model per observation / dataset\n",
    "    background = Map.read(path / \"background.fits.gz\")\n",
    "    background_model = BackgroundModel(background)\n",
    "    background_model.tilt.frozen = False\n",
    "    background_model.norm.value = 1.3\n",
    "\n",
    "    # optionally define a safe energy threshold\n",
    "    emin = None\n",
    "    mask_data = counts.geom.energy_mask(emin=emin)\n",
    "    mask = Map.from_geom(geom=counts.geom, data=mask_data)\n",
    "\n",
    "    dataset = MapDataset(\n",
    "        model=model,\n",
    "        counts=counts,\n",
    "        exposure=exposure,\n",
    "        psf=psf,\n",
    "        edisp=edisp,\n",
    "        background_model=background_model,\n",
    "        mask=mask,\n",
    "    )\n",
    "    \n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = Fit(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = fit.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best fit parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.datasets.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information which parameter belongs to which dataset is not listed explicitely in the table (yet), but the order of parameters is conserved. You can always access the underlying object tree as well to get specific parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset.background_model.norm.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(dataset):\n",
    "    npred = dataset.npred()\n",
    "    residual = (dataset.counts - npred).sum_over_axes().smooth(\"0.08 deg\")\n",
    "    _, ax, _ = residual.plot(\n",
    "        vmin=-0.5, vmax=0.5, cmap=\"coolwarm\", add_cbar=True, stretch=\"linear\"\n",
    "    )\n",
    "    x_center, y_center, _ = dataset.counts.geom.center_coord\n",
    "    fov = Circle(\n",
    "        (x_center, y_center), radius=4, transform=ax.get_transform(\"galactic\")\n",
    "    )\n",
    "    ax.images[0].set_clip_path(fov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each observation has different energy threshold. Keep in mind that the residuals are not meaningful below the energy threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(datasets[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we compute as stacked residual map (this requires to run the `analysis_3d` tutorial first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npred_stacked = Map.from_geom(geom)\n",
    "counts_stacked = Map.from_geom(geom)\n",
    "\n",
    "for dataset in datasets:\n",
    "    npred = dataset.npred()\n",
    "    coords = npred.geom.get_coord()\n",
    "\n",
    "    npred_stacked.fill_by_coord(coords, npred.data)\n",
    "    counts_stacked.fill_by_coord(coords, dataset.counts.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_stacked = (\n",
    "    (counts_stacked - npred_stacked).sum_over_axes().smooth(\"0.1 deg\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_stacked.plot(\n",
    "    vmin=-1, vmax=1, cmap=\"coolwarm\", add_cbar=True, stretch=\"linear\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
