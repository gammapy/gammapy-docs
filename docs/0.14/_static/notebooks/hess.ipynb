{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of H.E.S.S. DL3 data with Gammapy\n",
    "\n",
    "In September 2018 the [H.E.S.S.](https://www.mpi-hd.mpg.de/hfm/HESS) collaboration released a small subset of archival data in FITS format. This tutorial explains how to analyse this data with Gammapy. We will analyse four observation runs of the Crab nebula, which are part of the [H.E.S.S. first public test data release](https://www.mpi-hd.mpg.de/hfm/HESS/pages/dl3-dr1/). The data was release without corresponding background models. In [background_model.ipynb](background_model.ipynb) we show how to make a simple background model, which is also used in this tutorial. The background model is not perfect; it assumes radial symmetry and is in general derived from only a few observations, but still good enough for a reliable analysis > 1TeV.\n",
    "\n",
    "**Note:** The high level `Analysis` class is a new feature added in Gammapy v0.14. In the curret state it supports the standard analysis cases of a joint or stacked 3D and 1D analysis. It provides only limited access to analaysis parameters via the config file. It is expected that the format of the YAML config will be extended and change in future Gammapy versions.\n",
    "\n",
    "We will first show how to configure and run a stacked 3D analysis and then address the classical spectral analysis using reflected regions later. The structure of the tutorial follows a typical analysis:\n",
    "\n",
    "- Analysis configuration\n",
    "- Observation slection\n",
    "- Data reduction\n",
    "- Model fitting\n",
    "- Estimating flux points\n",
    "\n",
    "Finally we will compare the results against a reference model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from regions import CircleSkyRegion\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from gammapy.scripts import Analysis, AnalysisConfig\n",
    "from gammapy.modeling.models import create_crab_spectral_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis configuration\n",
    "\n",
    "For configuration of the analysis we use the [YAML](https://en.wikipedia.org/wiki/YAML) data format. YAML is a machine readable serialisation format, that is also friendly for humans to read. In this tutorial we will write the configuration file just using Python strings, but of course the file can be created and modified with any text editor of your choice.\n",
    "\n",
    "Here is what the configuration for our analysis looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_str = \"\"\"\n",
    "general:\n",
    "    logging:\n",
    "        level: INFO\n",
    "    outdir: .\n",
    "\n",
    "observations:\n",
    "    datastore: $GAMMAPY_DATA/hess-dl3-dr1/hess-dl3-dr3-with-background.fits.gz\n",
    "    filters:\n",
    "        - filter_type: par_value\n",
    "          value_param: Crab\n",
    "          variable: TARGET_NAME\n",
    "\n",
    "datasets:\n",
    "    dataset-type: MapDataset\n",
    "    stack-datasets: true\n",
    "    offset-max: 2.5 deg\n",
    "    geom:\n",
    "        skydir: [83.633, 22.014]\n",
    "        width: [5, 5]\n",
    "        binsz: 0.02\n",
    "        coordsys: CEL\n",
    "        proj: TAN\n",
    "        axes:\n",
    "          - name: energy\n",
    "            hi_bnd: 10\n",
    "            lo_bnd: 1\n",
    "            nbin: 5\n",
    "            interp: log\n",
    "            node_type: edges\n",
    "            unit: TeV\n",
    "\n",
    "fit:\n",
    "    fit_range:\n",
    "        max: 30 TeV\n",
    "        min: 1 TeV\n",
    "\n",
    "flux-points:\n",
    "    fp_binning:\n",
    "        lo_bnd: 1\n",
    "        hi_bnd: 10\n",
    "        interp: log\n",
    "        nbin: 3\n",
    "        unit: TeV\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create an `AnalysiConfig` object from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AnalysisConfig(config_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Observation selection\n",
    "\n",
    "Now we create the high level `Analysis` object from the config object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = Analysis(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And directly select and load the observatiosn from disk using `.get_observations()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations are now availabe on the `Analysis` object. The selection corresponds to the following ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.observations.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access and inspect individual observations by accessing with the observation id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.observations[\"23592\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also show a few overview plots using the `.peek()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.observations[\"23592\"].peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction\n",
    "\n",
    "Now we proceed to the data reduction. In the config file we have chosen a WCS map geometry, energy axis and decided to stack the maps. We can run the reduction using `.get_datasets()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis.get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have chosen to stack the data, there is finally one dataset contained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the dataset as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.datasets[\"stacked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the dataset comes with a predefined background model out of the data reduction, but no source model has been set yet.\n",
    "\n",
    "The counts, exposure and background model maps are directly available on the dataset and can be printed and plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = analysis.datasets[\"stacked\"].counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.smooth(\"0.05 deg\").plot_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "Now we define a model to be fitted to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = \"\"\"\n",
    "components:\n",
    "- name: crab\n",
    "  type: SkyModel\n",
    "  spatial:\n",
    "    type: PointSpatialModel\n",
    "    frame: icrs\n",
    "    parameters:\n",
    "    - name: lon_0\n",
    "      value: 83.63\n",
    "      unit: deg\n",
    "    - name: lat_0 \n",
    "      value: 22.14    \n",
    "      unit: deg\n",
    "  spectral:\n",
    "    type: PowerLawSpectralModel\n",
    "    parameters:\n",
    "    - name: amplitude      \n",
    "      value: 1.0e-12\n",
    "      unit: cm-2 s-1 TeV-1\n",
    "    - name: index\n",
    "      value: 2.0\n",
    "      unit: ''\n",
    "    - name: reference\n",
    "      value: 1.0\n",
    "      unit: TeV\n",
    "      frozen: true\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the model on the analysis object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.set_model(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.model[\"crab\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.run_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.fit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we can write the model back to file again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.model.to_yaml(\"model-best-fit.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat model-best-fit.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting residuals\n",
    "\n",
    "For any fit it is usefull to inspect the residual images. We have a few option on the dataset object to handle this. First we can use `.plot_residuals()` to plot a residual image, summed over all energies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].plot_residuals(\n",
    "    method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we can aslo specify a region in the map to show the spectral residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = CircleSkyRegion(\n",
    "    center=SkyCoord(\"83.63 deg\", \"22.14 deg\"), radius=0.5 * u.deg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].plot_residuals(\n",
    "    region=region, method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly access the `.residuals()` to get a map, that we can plot interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = analysis.datasets[\"stacked\"].residuals(method=\"diff\")\n",
    "residuals.smooth(\"0.08 deg\").plot_interactive(\n",
    "    cmap=\"coolwarm\", vmin=-0.1, vmax=0.1, stretch=\"linear\", add_cbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting likelihood profiles\n",
    "\n",
    "To check the quality of the fit it is also useful to plot likelihood profiles for specific parameters. For this we use `analysis.fit.likelihood_profile()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = analysis.fit.likelihood_profile(parameter=\"lon_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good fit and error estimate the profile should be parabolic, if we plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat = analysis.fit_result.total_stat\n",
    "plt.plot(profile[\"values\"], profile[\"likelihood\"] - total_stat)\n",
    "plt.xlabel(\"Lon (deg)\")\n",
    "plt.ylabel(\"Delta TS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.get_flux_points(source=\"crab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "ax_sed, ax_residuals = analysis.flux_points.peek()\n",
    "crab_spectrum = create_crab_spectral_model(\"hess_pl\")\n",
    "crab_spectrum.plot(\n",
    "    ax=ax_sed,\n",
    "    energy_range=[1, 10] * u.TeV,\n",
    "    energy_power=2,\n",
    "    flux_unit=\"erg-1 cm-2 s-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Run a spectral analysis using reflected regions without stacking the datasets. You can use `AnalysisConfig.from_template(\"1d\")` to get an example configuration file. Add the resulting flux points to the SED plotted above. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
