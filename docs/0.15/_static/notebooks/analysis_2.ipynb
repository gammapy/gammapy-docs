{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second analysis\n",
    "\n",
    "This notebook shows the same Crab analysis as performed in the [analysis_1 notebook](analysis_1.ipynb) but this time without the high level interface provided by the `Analysis` class. DL3 data release 1.\n",
    "\n",
    "As before, we will reduce the data to cube datasets and perform a simple 3D model fitting of the Crab nebula.\n",
    "\n",
    "The tutorial follows a typical analysis:\n",
    "\n",
    "- Observation selection\n",
    "- Data reduction\n",
    "- Model fitting\n",
    "- Estimating flux points\n",
    "\n",
    "but it gives more details on lower level API.\n",
    "\n",
    "First, we setup the analysis by performing required imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from regions import CircleSkyRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import DataStore\n",
    "from gammapy.maps import WcsGeom, MapAxis\n",
    "from gammapy.cube import MapDatasetMaker, MapDataset, SafeMaskMaker\n",
    "from gammapy.modeling.models import (\n",
    "    SkyModel,\n",
    "    PowerLawSpectralModel,\n",
    "    PointSpatialModel,\n",
    ")\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.spectrum import FluxPointsEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the datastore and selecting observations\n",
    "\n",
    "We first use the `~gammapy.data.DataStore` object to access the observations we want to analyse. Here the H.E.S.S. DL3 DR1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/hess-dl3-dr1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define an observation filter to select only the relevant observations. \n",
    "Here we use a cone search which we define with a python dict.\n",
    "\n",
    "We then filter the `ObservationTable` with `~gammapy.data.ObservationTable.select_observations()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = dict(\n",
    "    type=\"sky_circle\",\n",
    "    frame=\"icrs\",\n",
    "    lon=\"83.633 deg\",\n",
    "    lat=\"22.014 deg\",\n",
    "    radius=\"5 deg\",\n",
    ")\n",
    "selected_obs_table = data_store.obs_table.select_observations(selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now retrieve the relevant observations by passing their `obs_id` to the`~gammapy.data.DataStore.get_observations()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = data_store.get_observations(selected_obs_table[\"OBS_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing reduced datasets geometry\n",
    "\n",
    "Now we define a reference geometry for our analysis, We choose a WCS based geometry with a binsize of 0.02 deg and also define an energy axis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_axis = MapAxis.from_edges(\n",
    "    np.logspace(0.0, 1.0, 4), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(83.633, 22.014),\n",
    "    binsz=0.02,\n",
    "    width=(2, 2),\n",
    "    coordsys=\"CEL\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[energy_axis],\n",
    ")\n",
    "\n",
    "# Reduced IRFs are defined in true energy (i.e. not measured energy).\n",
    "energy_axis_true = MapAxis.from_edges(\n",
    "    np.logspace(-0.3, 1.3, 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the target dataset with this geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = MapDataset.create(\n",
    "    geom=geom, energy_axis_true=energy_axis_true, name=\"crab-stacked\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction\n",
    "\n",
    "### Create the maker classes to be used\n",
    "\n",
    "The `~gammapy.cube.MapDatasetMaker` object is initialized as well as the `~gammapy.cube.SafeMaskMaker` that carries here a maximum offset selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_max = 2.5 * u.deg\n",
    "maker = MapDatasetMaker()\n",
    "maker_safe_mask = SafeMaskMaker(methods=[\"offset-max\"], offset_max=offset_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the data reduction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for obs in observations:\n",
    "    # First a cutout of the target map is produced\n",
    "    cutout = stacked.cutout(obs.pointing_radec, width=2 * offset_max)\n",
    "    # A MapDataset is filled in this cutout geometry\n",
    "    dataset = maker.run(cutout, obs)\n",
    "    # The data quality cut is applied\n",
    "    dataset = maker_safe_mask.run(dataset, obs)\n",
    "    # The resulting dataset cutout is stacked onto the final one\n",
    "    stacked.stack(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n",
    "    stretch=\"sqrt\", add_cbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset to disk\n",
    "\n",
    "It is common to run the preparation step independent of the likelihood fit, because often the preparation of maps, PSF and energy dispersion is slow if you have a lot of data. We first create a folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"analysis_2\")\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then write the maps and IRFs to disk by calling the dedicated `~gammapy.cube.MapDataset.write()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filename = path / \"crab-stacked-dataset.fits.gz\"\n",
    "stacked.write(filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "We first define the model, a `SkyModel`, as the combination of a point source `SpatialModel` with a powerlaw `SpectralModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_position = SkyCoord(ra=83.63308, dec=22.01450, unit=\"deg\")\n",
    "spatial_model = PointSpatialModel(\n",
    "    lon_0=target_position.ra, lat_0=target_position.dec, frame=\"icrs\"\n",
    ")\n",
    "\n",
    "spectral_model = PowerLawSpectralModel(\n",
    "    index=2.702,\n",
    "    amplitude=4.712e-11 * u.Unit(\"1 / (cm2 s TeV)\"),\n",
    "    reference=1 * u.TeV,\n",
    ")\n",
    "\n",
    "sky_model = SkyModel(\n",
    "    spatial_model=spatial_model, spectral_model=spectral_model, name=\"crab\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we assign this model to our reduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.models = sky_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "The `~gammapy.modeling.Fit` class is orchestrating the fit, connecting the `stats` method of the dataset to the minimizer. By default, it uses `iminuit`.\n",
    "\n",
    "Its contructor takes a list of dataset as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit = Fit([stacked])\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FitResult` contains information on the fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting residuals\n",
    "\n",
    "For any fit it is usefull to inspect the residual images. We have a few option on the dataset object to handle this. First we can use `.plot_residuals()` to plot a residual image, summed over all energies: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.plot_residuals(method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we can aslo specify a region in the map to show the spectral residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = CircleSkyRegion(\n",
    "    center=SkyCoord(\"83.63 deg\", \"22.14 deg\"), radius=0.5 * u.deg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.plot_residuals(\n",
    "    region=region, method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly access the `.residuals()` to get a map, that we can plot interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = stacked.residuals(method=\"diff\")\n",
    "residuals.smooth(\"0.08 deg\").plot_interactive(\n",
    "    cmap=\"coolwarm\", vmin=-0.1, vmax=0.1, stretch=\"linear\", add_cbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting fit statistic profiles\n",
    "\n",
    "To check the quality of the fit it is also useful to plot fit statistic profiles for specific parameters.\n",
    "For this we use `~gammapy.modeling.Fit.stat_profile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = fit.stat_profile(parameter=\"lon_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good fit and error estimate the profile should be parabolic, if we plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stat = result.total_stat\n",
    "plt.plot(profile[\"values\"], profile[\"stat\"] - total_stat)\n",
    "plt.xlabel(\"Lon (deg)\")\n",
    "plt.ylabel(\"Delta TS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fitted spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a butterfly plot \n",
    "\n",
    "The `SpectralModel` component can be used to produce a, so-called, butterfly plot showing the enveloppe of the model taking into account parameter uncertainties.\n",
    "\n",
    "To do so, we have to copy the part of the covariance matrix stored on the `FitResult` on the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = sky_model.spectral_model\n",
    "\n",
    "# set covariance on the spectral model\n",
    "covar = result.parameters.get_subcovariance(spec.parameters)\n",
    "spec.parameters.covariance = covar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually do the plot using the `plot_error` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_range = [1, 10] * u.TeV\n",
    "spec.plot(energy_range=energy_range, energy_power=2)\n",
    "ax = spec.plot_error(energy_range=energy_range, energy_power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing flux points\n",
    "\n",
    "We can now compute some flux points using the `~gammapy.spectrum.FluxPointsEstimator`. \n",
    "\n",
    "Besides the list of datasets to use, we must provide it the energy intervals on which to compute flux points as well as the model component name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_edges = [1, 2, 4, 10] * u.TeV\n",
    "fpe = FluxPointsEstimator(datasets=[stacked], e_edges=e_edges, source=\"crab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "flux_points = fpe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = spec.plot_error(energy_range=energy_range, energy_power=2)\n",
    "flux_points.plot(ax=ax, energy_power=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
