{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTA data analysis with Gammapy\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**This notebook shows an example how to make a sky image and spectrum for simulated CTA data with Gammapy.**\n",
    "\n",
    "The dataset we will use is three observation runs on the Galactic center. This is a tiny (and thus quick to process and play with and learn) subset of the simulated CTA dataset that was produced for the first data challenge in August 2017.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As usual, we'll start with some setup ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gammapy info --no-envvar --no-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from regions import CircleSkyRegion\n",
    "from gammapy.modeling import Fit, Datasets\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.modeling.models import PowerLawSpectralModel, SkyModel\n",
    "from gammapy.spectrum import (\n",
    "    SpectrumDatasetMaker,\n",
    "    SpectrumDataset,\n",
    "    FluxPointsEstimator,\n",
    "    FluxPointsDataset,\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    "    plot_spectrum_datasets_off_regions,\n",
    ")\n",
    "from gammapy.maps import MapAxis, WcsNDMap, WcsGeom\n",
    "from gammapy.cube import MapDatasetMaker, MapDataset, SafeMaskMaker\n",
    "from gammapy.detect import TSMapEstimator, find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logger, so that the spectral analysis\n",
    "# isn't so chatty about what it's doing.\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "log = logging.getLogger(\"gammapy.spectrum\")\n",
    "log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select observations\n",
    "\n",
    "A Gammapy analysis usually starts by creating a `~gammapy.data.DataStore` and selecting observations.\n",
    "\n",
    "This is shown in detail in the other notebook, here we just pick three observations near the galactic center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/cta-1dc/index/gps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as a reminder: this is how to select observations\n",
    "# from astropy.coordinates import SkyCoord\n",
    "# table = data_store.obs_table\n",
    "# pos_obs = SkyCoord(table['GLON_PNT'], table['GLAT_PNT'], frame='galactic', unit='deg')\n",
    "# pos_target = SkyCoord(0, 0, frame='galactic', unit='deg')\n",
    "# offset = pos_target.separation(pos_obs).deg\n",
    "# mask = (1 < offset) & (offset < 2)\n",
    "# table = table[mask]\n",
    "# table.show_in_browser(jsviewer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_id = [110380, 111140, 111159]\n",
    "observations = data_store.get_observations(obs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cols = [\"OBS_ID\", \"GLON_PNT\", \"GLAT_PNT\", \"LIVETIME\"]\n",
    "data_store.obs_table.select_obs_id(obs_id)[obs_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sky images\n",
    "\n",
    "### Define map geometry\n",
    "\n",
    "Select the target position and define an ON region for the spectral analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = MapAxis.from_edges(\n",
    "    np.logspace(-1.0, 1.0, 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0), npix=(500, 400), binsz=0.02, coordsys=\"GAL\", axes=[axis]\n",
    ")\n",
    "geom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute images\n",
    "\n",
    "Exclusion mask currently unused. Remove here or move to later in the tutorial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_position = SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\")\n",
    "on_radius = 0.2 * u.deg\n",
    "on_region = CircleSkyRegion(center=target_position, radius=on_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_mask = geom.to_image().region_mask([on_region], inside=False)\n",
    "exclusion_mask = WcsNDMap(geom.to_image(), exclusion_mask)\n",
    "exclusion_mask.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stacked = MapDataset.create(geom=geom)\n",
    "maker = MapDatasetMaker(selection=[\"counts\", \"background\", \"exposure\"])\n",
    "maker_safe_mask = SafeMaskMaker(methods=[\"offset-max\"], offset_max=2.5 * u.deg)\n",
    "\n",
    "for obs in observations:\n",
    "    cutout = stacked.cutout(obs.pointing_radec, width=\"5 deg\")\n",
    "    dataset = maker.run(cutout, obs)\n",
    "    dataset = maker_safe_mask.run(dataset, obs)\n",
    "    stacked.stack(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maps are cubes, with an energy axis.\n",
    "# Let's also make some images:\n",
    "dataset_image = stacked.to_image()\n",
    "\n",
    "images = {\n",
    "    \"counts\": dataset_image.counts.get_image_by_idx((0,)),\n",
    "    \"exposure\": dataset_image.exposure.get_image_by_idx((0,)),\n",
    "    \"background\": dataset_image.background_model.map.get_image_by_idx((0,)),\n",
    "}\n",
    "\n",
    "images[\"excess\"] = images[\"counts\"] - images[\"background\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show images\n",
    "\n",
    "Let's have a quick look at the images we computed ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[\"counts\"].smooth(2).plot(vmax=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[\"background\"].plot(vmax=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[\"excess\"].smooth(3).plot(vmax=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Detection\n",
    "\n",
    "Use the class `~gammapy.detect.TSMapEstimator` and `~gammapy.detect.find_peaks` to detect sources on the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Gaussian2DKernel(1, mode=\"oversample\").array\n",
    "plt.imshow(kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ts_image_estimator = TSMapEstimator()\n",
    "images_ts = ts_image_estimator.run(images, kernel)\n",
    "print(images_ts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = find_peaks(images_ts[\"sqrt_ts\"], threshold=8)\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pos = SkyCoord(sources[\"ra\"], sources[\"dec\"])\n",
    "source_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sources on top of significance sky image\n",
    "images_ts[\"sqrt_ts\"].plot(add_cbar=True)\n",
    "\n",
    "plt.gca().scatter(\n",
    "    source_pos.ra.deg,\n",
    "    source_pos.dec.deg,\n",
    "    transform=plt.gca().get_transform(\"icrs\"),\n",
    "    color=\"none\",\n",
    "    edgecolor=\"white\",\n",
    "    marker=\"o\",\n",
    "    s=200,\n",
    "    lw=1.5,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial analysis\n",
    "\n",
    "See other notebooks for how to run a 3D cube or 2D image based analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum\n",
    "\n",
    "We'll run a spectral analysis using the classical reflected regions background estimation method,\n",
    "and using the on-off (often called WSTAT) likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_reco = np.logspace(-1, np.log10(40), 40) * u.TeV\n",
    "e_true = np.logspace(np.log10(0.05), 2, 200) * u.TeV\n",
    "\n",
    "dataset_empty = SpectrumDataset.create(\n",
    "    e_reco=e_reco, e_true=e_true, region=on_region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=False, selection=[\"counts\", \"aeff\", \"edisp\"]\n",
    ")\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(exclusion_mask=exclusion_mask)\n",
    "safe_mask_masker = SafeMaskMaker(methods=[\"aeff-max\"], aeff_percent=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "datasets = []\n",
    "\n",
    "for observation in observations:\n",
    "    dataset = dataset_maker.run(dataset_empty, observation)\n",
    "    dataset_on_off = bkg_maker.run(dataset, observation)\n",
    "    dataset_on_off = safe_mask_masker.run(dataset_on_off, observation)\n",
    "    datasets.append(dataset_on_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "_, ax, _ = images[\"counts\"].smooth(\"0.03 deg\").plot(vmax=8)\n",
    "\n",
    "on_region.to_pixel(ax.wcs).plot(ax=ax, edgecolor=\"white\")\n",
    "plot_spectrum_datasets_off_regions(datasets, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit\n",
    "\n",
    "The next step is to fit a spectral model, using all data (i.e. a \"global\" fit, using all energies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spectral_model = PowerLawSpectralModel(\n",
    "    index=2, amplitude=1e-11 * u.Unit(\"cm-2 s-1 TeV-1\"), reference=1 * u.TeV\n",
    ")\n",
    "model = SkyModel(spectral_model=spectral_model)\n",
    "for dataset in datasets:\n",
    "    dataset.models = model\n",
    "\n",
    "fit = Fit(datasets)\n",
    "result = fit.run()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral points\n",
    "\n",
    "Finally, let's compute spectral points. The method used is to first choose an energy binning, and then to do a 1-dim likelihood fit / profile to compute the flux and flux error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flux points are computed on stacked observation\n",
    "stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "\n",
    "print(stacked_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_edges = np.logspace(0, 1.5, 5) * u.TeV\n",
    "\n",
    "stacked_dataset.model = model\n",
    "\n",
    "fpe = FluxPointsEstimator(datasets=[stacked_dataset], e_edges=e_edges)\n",
    "flux_points = fpe.run()\n",
    "flux_points.table_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot\n",
    "\n",
    "Let's plot the spectral model and points. You could do it directly, but there is a helper class.\n",
    "Note that a spectral uncertainty band, a \"butterfly\" is drawn, but it is very thin, i.e. barely visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.spectral_model.parameters.covariance = result.parameters.covariance\n",
    "flux_points_dataset = FluxPointsDataset(data=flux_points, models=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "flux_points_dataset.peek();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Re-run the analysis above, varying some analysis parameters, e.g.\n",
    "    * Select a few other observations\n",
    "    * Change the energy band for the map\n",
    "    * Change the spectral model for the fit\n",
    "    * Change the energy binning for the spectral points\n",
    "* Change the target. Make a sky image and spectrum for your favourite source.\n",
    "    * If you don't know any, the Crab nebula is the \"hello world!\" analysis of gamma-ray astronomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('hello world')\n",
    "# SkyCoord.from_name('crab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "* This notebook showed an example of a first CTA analysis with Gammapy, using simulated 1DC data.\n",
    "* Let us know if you have any question or issues!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
