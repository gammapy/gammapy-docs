{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D simulation and fitting\n",
    "\n",
    "This tutorial shows how to do a 3D map-based simulation and fit.\n",
    "\n",
    "For a tutorial on how to do a 3D map analyse of existing data, see the [analysis_3d](analysis_3d.ipynb) tutorial.\n",
    "\n",
    "This can be useful to do a performance / sensitivity study, or to evaluate the capabilities of Gammapy or a given analysis method. Note that is is a binned simulation as is e.g. done also in Sherpa for Chandra, not an event sampling and anbinned analysis as is done e.g. in the Fermi ST or ctools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.maps import WcsGeom, MapAxis\n",
    "from gammapy.modeling.models import PowerLawSpectralModel\n",
    "from gammapy.modeling.models import GaussianSpatialModel\n",
    "from gammapy.modeling.models import SkyModel\n",
    "from gammapy.cube import MapDataset, MapDatasetMaker, SafeMaskMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.data import Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gammapy info --no-envvar --no-dependencies --no-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate using the CTA-1DC IRFs shipped with gammapy. Note that for dedictaed CTA simulations, you can simply use [`Observation.from_caldb()`]() without having to externally load the IRFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading IRFs\n",
    "irfs = load_cta_irfs(\n",
    "    \"$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the observation parameters (typically the observation duration and the pointing position):\n",
    "livetime = 2.0 * u.hr\n",
    "pointing = SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map geometry for binned simulation\n",
    "energy_reco = MapAxis.from_edges(\n",
    "    np.logspace(-1.0, 1.0, 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0), binsz=0.02, width=(6, 6), coordsys=\"GAL\", axes=[energy_reco]\n",
    ")\n",
    "# It is usually useful to have a separate binning for the true energy axis\n",
    "energy_true = MapAxis.from_edges(\n",
    "    np.logspace(-1.5, 1.5, 30), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sky model to used simulate the data.\n",
    "# Here we use a Gaussian spatial model and a Power Law spectral model.\n",
    "spatial_model = GaussianSpatialModel(\n",
    "    lon_0=\"0.2 deg\", lat_0=\"0.1 deg\", sigma=\"0.3 deg\", frame=\"galactic\"\n",
    ")\n",
    "spectral_model = PowerLawSpectralModel(\n",
    "    index=3, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "model_simu = SkyModel(\n",
    "    spatial_model=spatial_model,\n",
    "    spectral_model=spectral_model,\n",
    "    name=\"model_simu\",\n",
    ")\n",
    "print(model_simu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, comes the main part of dataset simulation. We create an in-memory observation and an empty dataset. We then predict the number of counts for the given model, and Poission fluctuate it using `fake()` to make a simulated counts maps. Keep in mind that it is important to specify the `selection` of the maps that you want to produce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an in-memory observation\n",
    "obs = Observation.create(pointing=pointing, livetime=livetime, irfs=irfs)\n",
    "print(obs)\n",
    "# Make the MapDataset\n",
    "empty = MapDataset.create(geom)\n",
    "maker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\n",
    "maker_safe_mask = SafeMaskMaker(methods=[\"offset-max\"], offset_max=4.0 * u.deg)\n",
    "dataset = maker.run(empty, obs)\n",
    "dataset = maker_safe_mask.run(dataset, obs)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the model on the dataset and Poission fluctuate\n",
    "dataset.models = model_simu\n",
    "dataset.fake()\n",
    "# Do a print on the dataset - there is now a counts maps\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this dataset as you would in all standard analysis. You can plot the maps, or proceed with your custom analysis. \n",
    "In the next section, we show the standard 3D fitting as in [analysis_3d](analysis_3d.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot, eg, counts:\n",
    "dataset.counts.smooth(0.05 * u.deg).plot_interactive(\n",
    "    add_cbar=True, stretch=\"linear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "In this section, we do a usual 3D fit with the same model used to simulated the data and see the stability of the simulations. Often, it is useful to simulate many such datasets and look at the distribution of the reconstructed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataset\n",
    "dataset1 = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sky model to fit the data\n",
    "spatial_model1 = GaussianSpatialModel(\n",
    "    lon_0=\"0.1 deg\", lat_0=\"0.1 deg\", sigma=\"0.5 deg\", frame=\"galactic\"\n",
    ")\n",
    "spectral_model1 = PowerLawSpectralModel(\n",
    "    index=2, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "model_fit = SkyModel(\n",
    "    spatial_model=spatial_model1,\n",
    "    spectral_model=spectral_model1,\n",
    "    name=\"model_fit\",\n",
    ")\n",
    "\n",
    "dataset1.models = model_fit\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not want to fit the background in this case, so we will freeze the parameters\n",
    "background_model = dataset1.background_model\n",
    "background_model.parameters[\"norm\"].value = 1.0\n",
    "background_model.parameters[\"norm\"].frozen = True\n",
    "background_model.parameters[\"tilt\"].frozen = True\n",
    "\n",
    "print(background_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit = Fit([dataset1])\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.plot_residuals(method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the injected and fitted models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True model: \\n\", model_simu, \"\\n\\n Fitted model: \\n\", model_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the errors on the fitted parameters from the parameter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.parameters.to_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
