{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D simulation and fitting\n",
    "\n",
    "This tutorial shows how to do a 3D map-based simulation and fit.\n",
    "\n",
    "For a tutorial on how to do a 3D map analyse of existing data, see the `analysis_3d` tutorial.\n",
    "\n",
    "This can be useful to do a performance / sensitivity study, or to evaluate the capabilities of Gammapy or a given analysis method. Note that is is a binned simulation as is e.g. done also in Sherpa for Chandra, not an event sampling and anbinned analysis as is done e.g. in the Fermi ST or ctools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from gammapy.irf import (\n",
    "    EffectiveAreaTable2D,\n",
    "    EnergyDispersion2D,\n",
    "    EnergyDependentMultiGaussPSF,\n",
    "    Background3D,\n",
    ")\n",
    "from gammapy.maps import WcsGeom, MapAxis, WcsNDMap, Map\n",
    "from gammapy.spectrum.models import PowerLaw\n",
    "from gammapy.image.models import SkyGaussian\n",
    "from gammapy.cube.models import SkyModel, SkyModels\n",
    "from gammapy.cube import MapFit, MapEvaluator, PSFKernel\n",
    "from gammapy.cube import make_map_exposure_true_energy, make_map_background_irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gammapy info --no-envvar --no-dependencies --no-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irfs():\n",
    "    \"\"\"Load CTA IRFs\"\"\"\n",
    "    filename = \"$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits\"\n",
    "    psf = EnergyDependentMultiGaussPSF.read(\n",
    "        filename, hdu=\"POINT SPREAD FUNCTION\"\n",
    "    )\n",
    "    aeff = EffectiveAreaTable2D.read(filename, hdu=\"EFFECTIVE AREA\")\n",
    "    edisp = EnergyDispersion2D.read(filename, hdu=\"ENERGY DISPERSION\")\n",
    "    bkg = Background3D.read(filename, hdu=\"BACKGROUND\")\n",
    "    return dict(psf=psf, aeff=aeff, edisp=edisp, bkg=bkg)\n",
    "\n",
    "\n",
    "irfs = get_irfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sky model to simulate the data\n",
    "spatial_model = SkyGaussian(lon_0=\"0.2 deg\", lat_0=\"0.1 deg\", sigma=\"0.3 deg\")\n",
    "spectral_model = PowerLaw(\n",
    "    index=3, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "sky_model = SkyModel(\n",
    "    spatial_model=spatial_model, spectral_model=spectral_model\n",
    ")\n",
    "print(sky_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map geometry\n",
    "axis = MapAxis.from_edges(\n",
    "    np.logspace(-1., 1., 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0), binsz=0.02, width=(5, 4), coordsys=\"GAL\", axes=[axis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some observation parameters\n",
    "# Here we just have a single observation,\n",
    "# we are not simulating many pointings / observations\n",
    "pointing = SkyCoord(1, 0.5, unit=\"deg\", frame=\"galactic\")\n",
    "livetime = 1 * u.hour\n",
    "offset_max = 2 * u.deg\n",
    "offset = Angle(\"2 deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = make_map_exposure_true_energy(\n",
    "    pointing=pointing, livetime=livetime, aeff=irfs[\"aeff\"], geom=geom\n",
    ")\n",
    "exposure.slice_by_idx({\"energy\": 3}).plot(add_cbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = make_map_background_irf(\n",
    "    pointing=pointing, livetime=livetime, bkg=irfs[\"bkg\"], geom=geom\n",
    ")\n",
    "background.slice_by_idx({\"energy\": 3}).plot(add_cbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = irfs[\"psf\"].to_energy_dependent_table_psf(theta=offset)\n",
    "psf_kernel = PSFKernel.from_table_psf(psf, geom, max_radius=0.3 * u.deg)\n",
    "psf_kernel.psf_kernel_map.sum_over_axes().plot(stretch=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edisp = irfs[\"edisp\"].to_energy_dispersion(offset=offset)\n",
    "edisp.plot_matrix();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# The idea is that we have this class that can compute `npred`\n",
    "# maps, i.e. \"predicted counts per pixel\" given the model and\n",
    "# the observation infos: exposure, background, PSF and EDISP\n",
    "evaluator = MapEvaluator(\n",
    "    model=sky_model, exposure=exposure, background=background, psf=psf_kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing and saving a lot of the following maps is for debugging.\n",
    "# Just for a simulation one doesn't need to store all these things.\n",
    "# dnde = evaluator.compute_dnde()\n",
    "# flux = evaluator.compute_flux()\n",
    "npred = evaluator.compute_npred()\n",
    "npred_map = WcsNDMap(geom, npred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npred_map.sum_over_axes().plot(add_cbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one line is the core of how to simulate data when\n",
    "# using binned simulation / analysis: you Poisson fluctuate\n",
    "# npred to obtain simulated observed counts.\n",
    "# Compute counts as a Poisson fluctuation\n",
    "rng = np.random.RandomState(seed=42)\n",
    "counts = rng.poisson(npred)\n",
    "counts_map = WcsNDMap(geom, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_map.sum_over_axes().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "Now let's analyse the simulated data.\n",
    "Here we just fit it again with the same model we had before, but you could do any analysis you like here, e.g. fit a different model, or do a region-based analysis, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sky model to fit the data\n",
    "spatial_model = SkyGaussian(lon_0=\"0 deg\", lat_0=\"0 deg\", sigma=\"1 deg\")\n",
    "spectral_model = PowerLaw(\n",
    "    index=2, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit = MapFit(\n",
    "    model=model,\n",
    "    counts=counts_map,\n",
    "    exposure=exposure,\n",
    "    background=background,\n",
    "    psf=psf_kernel,\n",
    ")\n",
    "\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sky_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best-fit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show e.g. how to make a residual image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iminuit\n",
    "\n",
    "What we have done for now is to write a very thin wrapper for http://iminuit.readthedocs.io/\n",
    "as a fitting backend. This is just a prototype, we will improve this interface and\n",
    "add other fitting backends (e.g. Sherpa or scipy.optimize or emcee or ...)\n",
    "\n",
    "As a power-user, you can access ``fit._iminuit`` and get the full power of what is developed there already.\n",
    "E.g. the ``fit.fit()`` call ran ``Minuit.migrad()`` and ``Minuit.hesse()`` in the background, and you have\n",
    "access to e.g. the covariance matrix, or can check a likelihood profile, or can run ``Minuit.minos()``\n",
    "to compute asymmetric errors or ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between model parameters\n",
    "# As expected in this simple case,\n",
    "# spatial parameters are uncorrelated,\n",
    "# but the spectral model amplitude and index are correlated as always\n",
    "fit.minuit.print_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use likelihood profiles to check if your model is\n",
    "# well constrained or not, and if the fit really converged\n",
    "fit.minuit.draw_profile(\"par_002_sigma\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
