{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Datasets - Reduced data, IRFs, models\n\nLearn how to work with datasets\n\n## Introduction\n\n`~gammapy.datasets` are a crucial part of the gammapy API. `~gammapy.datasets.Dataset`\nobjects constitute `DL4` data - binned counts, IRFs, models and the associated\nlikelihoods. `~gammapy.datasets.Datasets` from the end product of the data reduction stage,\nsee :doc:`/tutorials/api/makers` tutorial and are passed on to the `~gammapy.modeling.Fit`\nor estimator classes for modelling and fitting purposes.\n\nTo find the different types of `~gammapy.datasets.Dataset` objects that are supported see\n`datasets-types`:\n\n## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import astropy.units as u\nfrom astropy.coordinates import SkyCoord\nfrom regions import CircleSkyRegion\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom gammapy.data import GTI\nfrom gammapy.datasets import (\n    Datasets,\n    FluxPointsDataset,\n    MapDataset,\n    SpectrumDatasetOnOff,\n)\nfrom gammapy.estimators import FluxPoints\nfrom gammapy.maps import MapAxis, WcsGeom\nfrom gammapy.modeling.models import FoVBackgroundModel, PowerLawSpectralModel, SkyModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\nfrom gammapy.utils.scripts import make_path\n\n# %matplotlib inline\n\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MapDataset\n\nThe counts, exposure, background, masks, and IRF maps are bundled\ntogether in a data structure named `~gammapy.datasets.MapDataset`. While the `counts`,\nand `background` maps are binned in reconstructed energy and must have\nthe same geometry, the IRF maps can have a different spatial (coarsely\nbinned and larger) geometry and spectral range (binned in true\nenergies). It is usually recommended that the true energy bin should be\nlarger and more finely sampled and the reco energy bin.\n\n### Creating an empty dataset\n\nAn empty `~gammapy.datasets.MapDataset` can be directly instantiated from any\n`~gammapy.maps.WcsGeom` object:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis = MapAxis.from_energy_bounds(1, 10, nbin=11, name=\"energy\", unit=\"TeV\")\n\ngeom = WcsGeom.create(\n    skydir=(83.63, 22.01),\n    axes=[energy_axis],\n    width=5 * u.deg,\n    binsz=0.05 * u.deg,\n    frame=\"icrs\",\n)\n\ndataset_empty = MapDataset.create(geom=geom, name=\"my-dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is good practice to define a name for the dataset, such that you can\nidentify it later by name. However if you define a name it **must** be\nunique. Now we can already print the dataset:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_empty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The printout shows the key summary information of the dataset, such as\ntotal counts, fit statistics, model information etc.\n\n`~gammapy.datasetsMapDataset.from_geom` has additional keywords, that can be used to\ndefine the binning of the IRF related maps:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# choose a different true energy binning for the exposure, psf and edisp\nenergy_axis_true = MapAxis.from_energy_bounds(\n    0.1, 100, nbin=11, name=\"energy_true\", unit=\"TeV\", per_decade=True\n)\n\n# choose a different rad axis binning for the psf\nrad_axis = MapAxis.from_bounds(0, 5, nbin=50, unit=\"deg\", name=\"rad\")\n\ngti = GTI.create(0 * u.s, 1000 * u.s)\n\ndataset_empty = MapDataset.create(\n    geom=geom,\n    energy_axis_true=energy_axis_true,\n    rad_axis=rad_axis,\n    binsz_irf=0.1,\n    gti=gti,\n    name=\"dataset-empty\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see the geometry of each map, we can use:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_empty.geoms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another way to create a `~gammapy.datasets.MapDataset` is to just read an existing one\nfrom a FITS file:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_cta = MapDataset.read(\n    \"$GAMMAPY_DATA/cta-1dc-gc/cta-1dc-gc.fits.gz\", name=\"dataset-cta\"\n)\n\nprint(dataset_cta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accessing contents of a dataset\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To further explore the contents of a `Dataset`, you can use\ne.g.\u00a0`~gammay.datasets.MapDataset.info_dict()`\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a quick info, use\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_cta.info_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a quick view, use\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_cta.peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And access individual maps like:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\ncounts_image = dataset_cta.counts.sum_over_axes()\ncounts_image.smooth(\"0.1 deg\").plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course you can also access IRF related maps, e.g.\u00a0the psf as\n`~gammapy.irf.PSFMap`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_cta.psf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And use any method on the `~gammapy.irf.PSFMap` object:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "radius = dataset_cta.psf.containment_radius(energy_true=1 * u.TeV, fraction=0.95)\nprint(radius)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nedisp_kernel = dataset_cta.edisp.get_edisp_kernel()\nedisp_kernel.plot_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `~gammapy.datasets.MapDataset` typically also contains the information on the\nresidual hadronic background, stored in `~gammapy.datasets.MapDataset.background` as a\nmap:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_cta.background)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a next step we define a minimal model on the dataset using the\n`~gammapy.datasets.MapDataset.models` setter:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = SkyModel.create(\"pl\", \"point\", name=\"gc\")\nmodel.spatial_model.position = SkyCoord(\"0d\", \"0d\", frame=\"galactic\")\nmodel_bkg = FoVBackgroundModel(dataset_name=\"dataset-cta\")\n\ndataset_cta.models = [model, model_bkg]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assigning models to datasets is covered in more detail in :doc:`/tutorials/api/model_management`.\nPrinting the dataset will now show the model components:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_cta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can use the `~gammapy.datasets.MapDataset.npred` method to get a map of the total predicted counts\nof the model:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nnpred = dataset_cta.npred()\nnpred.sum_over_axes().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get the predicted counts from an individual model component we can\nuse:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nnpred_source = dataset_cta.npred_signal(model_name=\"gc\")\nnpred_source.sum_over_axes().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`~gammapy.datasets.MapDataset.background` contains the background map computed from the\nIRF. Internally it will be combined with a `~gammapy.modeling.models.FoVBackgroundModel`, to\nallow for adjusting the background model during a fit. To get the model\ncorrected background, one can use `~gammapy.datasets.MapDataset.npred_background`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nnpred_background = dataset_cta.npred_background()\nnpred_background.sum_over_axes().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using masks\n\nThere are two masks that can be set on a `~gammapy.datasets.MapDataset`, `~gammapy.datasets.MapDataset.mask_safe` and\n`~gammapy.datasets.MapDataset.mask_fit`.\n\n-  The `~gammapy.datasets.MapDataset.mask_safe` is computed during the data reduction process\n   according to the specified selection cuts, and should not be changed\n   by the user.\n-  During modelling and fitting, the user might want to additionally\n   ignore some parts of a reduced dataset, e.g.\u00a0to restrict the fit to a\n   specific energy range or to ignore parts of the region of interest.\n   This should be done by applying the `~gammapy.datasets.MapDataset.mask_fit`. To see details of\n   applying masks, please refer to `masks-for-fitting`.\n\nBoth the `~gammapy.datasets.MapDataset.mask_fit` and `~gammapy.datasets.MapDataset.mask_safe` must\nhave the same `~gammapy.maps.Map.geom` as the `~gammapy.datasets.MapDataset.counts` and `~gammapy.datasets.MapDataset.background` maps.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# eg: to see the safe data range\n\n# plt.figure()\ndataset_cta.mask_safe.plot_grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition it is possible to define a custom `~gammapy.datasets.MapDataset.mask_fit`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To apply a mask fit - in enegy and space\n\nregion = CircleSkyRegion(SkyCoord(\"0d\", \"0d\", frame=\"galactic\"), 1.5 * u.deg)\n\ngeom = dataset_cta.counts.geom\n\nmask_space = geom.region_mask([region])\nmask_energy = geom.energy_mask(0.3 * u.TeV, 8 * u.TeV)\ndataset_cta.mask_fit = mask_space & mask_energy\ndataset_cta.mask_fit.plot_grid(vmin=0, vmax=1, add_cbar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To access the energy range defined by the mask you can use:\n\n-`~gammapy.datasets.MapDataset.energy_range_safe` : energy range definedby the `~gammapy.datasets.MapDataset.mask_safe`\n- `~gammapy.datasets.MapDataset.energy_range_fit` : energy range defined by the `~gammapy.datasets.MapDataset.mask_fit`\n- `~gammapy.datasets.MapDataset.energy_range` : the final energy range used in likelihood computation\n\nThese methods return two maps, with the `min` and `max` energy\nvalues at each spatial pixel\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "e_min, e_max = dataset_cta.energy_range\n\n# To see the low energy threshold at each point\n\nplt.figure()\ne_min.plot(add_cbar=True)\n\n# To see the high energy threshold at each point\n\nplt.figure()\ne_max.plot(add_cbar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just as for `~gammapy.maps.Map` objects it is possible to cutout a whole\n`~gammapy.datasets.MapDataset`, which will perform the cutout for all maps in\nparallel.Optionally one can provide a new name to the resulting dataset:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cutout = dataset_cta.cutout(\n    position=SkyCoord(\"0d\", \"0d\", frame=\"galactic\"),\n    width=2 * u.deg,\n    name=\"cta-cutout\",\n)\n\nplt.figure()\ncutout.counts.sum_over_axes().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to slice a `~gammapy.datasets.MapDataset` in energy:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sliced = dataset_cta.slice_by_energy(\n    energy_min=1 * u.TeV, energy_max=5 * u.TeV, name=\"slice-energy\"\n)\nsliced.counts.plot_grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same operation will be applied to all other maps contained in the\ndatasets such as `~gammapy.datasets.MapDataset.mask_fit`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sliced.mask_fit.plot_grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resampling datasets\n\nIt can often be useful to coarsely rebin an initially computed datasets\nby a specified factor. This can be done in either spatial or energy\naxes:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\ndownsampled = dataset_cta.downsample(factor=8)\ndownsampled.counts.sum_over_axes().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the same downsampling process is possible along the energy axis:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "downsampled_energy = dataset_cta.downsample(\n    factor=5, axis_name=\"energy\", name=\"downsampled-energy\"\n)\ndownsampled_energy.counts.plot_grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the printout one can see that the actual number of counts is\npreserved during the downsampling:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(downsampled_energy, dataset_cta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also resample the finer binned datasets to an arbitrary coarser\nenergy binning using:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis_new = MapAxis.from_energy_edges([0.1, 0.3, 1, 3, 10] * u.TeV)\nresampled = dataset_cta.resample_energy_axis(energy_axis=energy_axis_new)\nresampled.counts.plot_grid(ncols=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To squash the whole dataset into a single energy bin there is the\n`~gammapy.datasets.MapDataset.to_image()` convenience method:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\ndataset_image = dataset_cta.to_image()\ndataset_image.counts.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SpectrumDataset\n\n`~gammapy.datasets.SpectrumDataset` inherits from a `~gammapy.datasets.MapDataset`, and is specially\nadapted for 1D spectral analysis, and uses a `RegionGeom` instead of a\n`WcsGeom`. A `~gammapy.datasets.MapDatset` can be converted to a `~gammapy.datasets.SpectrumDataset`,\nby summing the `counts` and `background` inside the `on_region`,\nwhich can then be used for classical spectral analysis. Containment\ncorrection is feasible only for circular regions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "region = CircleSkyRegion(SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\"), 0.5 * u.deg)\nspectrum_dataset = dataset_cta.to_spectrum_dataset(\n    region, containment_correction=True, name=\"spectrum-dataset\"\n)\n\n# For a quick look\nspectrum_dataset.peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A `~gammapy.datasets.MapDataset` can also be integrated over the `on_region` to create\na `~gammapy.datasets.MapDataset` with a `~gammapy.maps.RegionGeom`. Complex regions can be handled\nand since the full IRFs are used, containment correction is not\nrequired.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg_dataset = dataset_cta.to_region_map_dataset(region, name=\"region-map-dataset\")\nprint(reg_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FluxPointsDataset\n\n`~gammapy.datasets.FluxPointsDataset` is a `~gammapy.datasets.Dataset` container for precomputed flux\npoints, which can be then used in fitting.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nflux_points = FluxPoints.read(\n    \"$GAMMAPY_DATA/tests/spectrum/flux_points/diff_flux_points.fits\"\n)\nmodel = SkyModel(spectral_model=PowerLawSpectralModel(index=2.3))\nfp_dataset = FluxPointsDataset(data=flux_points, models=model)\n\nfp_dataset.plot_spectrum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masks on `~gammapy.datasets.FluxPointsDataset` are `~numpy.ndarray` objects\nand the data is a\n`~gammapy.datasets.FluxPoints` object. The `~gammapy.datasets.FluxPointsDataset.mask_safe`, by default, masks the upper\nlimit points\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(fp_dataset.mask_safe)  # Note: the mask here is simply a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(fp_dataset.data)  # is a `FluxPoints` object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(fp_dataset.data_shape())  # number of data points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For an example of fitting `~gammapy.estimators.FluxPoints`, see :doc:`/tutorials/analysis-1d/sed_fitting`,\nand for using source catalogs see :doc:`/tutorials/api/catalog`\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datasets\n\n`~gammapy.datasets.Datasets` are a collection of `~gammapy.datasets.Dataset` objects. They can be of the\nsame type, or of different types, eg: mix of `~gammapy.datasets.FluxPointsDataset`,\n`~gammapy.datasets.MapDataset` and `~gammapy.datasets.SpectrumDataset`.\n\nFor modelling and fitting of a list of `~gammapy.datasets.Dataset` objects, you can\neither:\n(a) Do a joint fitting of all the datasets together OR\n(b) Stack the datasets together, and then fit them.\n\n`~gammapy.datasets.Datasets` is a convenient tool to handle joint fitting of\nsimultaneous datasets. As an example, please see :doc:`/tutorials/analysis-3d/analysis_mwl`\n\nTo see how stacking is performed, please see `stack`.\n\nTo create a `~gammapy.datasets.Datasets` object, pass a list of `~gammapy.datasets.Dataset` on init, eg\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = Datasets([dataset_empty, dataset_cta])\n\nprint(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If all the datasets have the same type we can also print an info table,\ncollectiong all the information from the individual calls to\n`~gammapy.datasets.Dataset.info_dict()`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(datasets.info_table())  # quick info of all datasets\n\nprint(datasets.names)  # unique name of each dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access individual datasets in `Datasets` object by name:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(datasets[\"dataset-empty\"])  # extracts the first dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or by index:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(datasets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Other list type operations work as well such as:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use python list convention to remove/add datasets, eg:\ndatasets.remove(\"dataset-empty\")\nprint(datasets.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets.append(spectrum_dataset)\nprint(datasets.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s create a list of spectrum datasets to illustrate some more\nfunctionality:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = Datasets()\n\npath = make_path(\"$GAMMAPY_DATA/joint-crab/spectra/hess\")\n\nfor filename in path.glob(\"pha_*.fits\"):\n    dataset = SpectrumDatasetOnOff.read(filename)\n    datasets.append(dataset)\n\nprint(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can stack all datasets using `~gammapy.datasets.Datasets.stack_reduce()`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stacked = datasets.stack_reduce(name=\"stacked\")\nprint(stacked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or slice all datasets by a given energy range:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets_sliced = datasets.slice_by_energy(energy_min=\"1 TeV\", energy_max=\"10 TeV\")\nprint(datasets_sliced.energy_ranges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}