{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Ring background map\n\nCreate an excess (gamma-ray events) and a significance map extracting a ring background.\n\n## Context\n\nOne of the challenges of IACT analysis is accounting for the large\nresidual hadronic emission. An excess map, assumed to be a map of only\ngamma-ray events, requires a good estimate of the background. However,\nin the absence of a solid template bkg model it is not possible to\nobtain reliable background model a priori. It was often found necessary\nin classical cherenkov astronomy to perform a local renormalization of\nthe existing templates, usually with a ring kernel. This assumes that\nmost of the events are background and requires to have an exclusion mask\nto remove regions with bright signal from the estimation. To read more\nabout this method, see\n[here.](https://arxiv.org/abs/astro-ph/0610959)_\n\n## Objective\n\nCreate an excess (gamma-ray events) map of MSH 15-52 as well as a\nsignificance map to determine how solid the signal is.\n\n## Proposed approach\n\nThe analysis workflow is roughly:\n\n- Compute the sky maps keeping each observation separately using the `Analysis` class\n- Estimate the background using the `RingBackgroundMaker`\n- Compute the correlated excess and significance maps using the `ExcessMapEstimator`\n\nThe normalised background thus obtained can be used for general\nmodelling and fitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nAs usual, we\u2019ll start with some general imports\u2026\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport numpy as np\nfrom scipy.stats import norm\n\n# %matplotlib inline\nimport astropy.units as u\nfrom astropy.coordinates import SkyCoord\nfrom regions import CircleSkyRegion\nimport matplotlib.pyplot as plt\nfrom gammapy.analysis import Analysis, AnalysisConfig\nfrom gammapy.datasets import MapDatasetOnOff\nfrom gammapy.estimators import ExcessMapEstimator\nfrom gammapy.makers import RingBackgroundMaker\n\nlog = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the config file\n\nNow, we create a config file for out analysis. You may load this from\ndisc if you have a pre-defined config file.\n\nIn this example, we will use a few HESS runs on the pulsar wind nebula,\nMSH 1552\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# source_pos = SkyCoord.from_name(\"MSH 15-52\")\nsource_pos = SkyCoord(228.32, -59.08, unit=\"deg\")\n\nconfig = AnalysisConfig()\n# Select observations - 2.5 degrees from the source position\nconfig.observations.datastore = \"$GAMMAPY_DATA/hess-dl3-dr1/\"\nconfig.observations.obs_cone = {\n    \"frame\": \"icrs\",\n    \"lon\": source_pos.ra,\n    \"lat\": source_pos.dec,\n    \"radius\": 2.5 * u.deg,\n}\n\nconfig.datasets.type = \"3d\"\nconfig.datasets.geom.wcs.skydir = {\n    \"lon\": source_pos.ra,\n    \"lat\": source_pos.dec,\n    \"frame\": \"icrs\",\n}  # The WCS geometry - centered on MSH 15-52\nconfig.datasets.geom.wcs.width = {\"width\": \"3 deg\", \"height\": \"3 deg\"}\nconfig.datasets.geom.wcs.binsize = \"0.02 deg\"\n\n# Cutout size (for the run-wise event selection)\nconfig.datasets.geom.selection.offset_max = 3.5 * u.deg\n\n# We now fix the energy axis for the counts map - (the reconstructed energy binning)\nconfig.datasets.geom.axes.energy.min = \"0.5 TeV\"\nconfig.datasets.geom.axes.energy.max = \"5 TeV\"\nconfig.datasets.geom.axes.energy.nbins = 10\n\n# We need to extract the ring for each observation separately, hence, no stacking at this stage\nconfig.datasets.stack = False\n\nprint(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting the reduced dataset\n\nWe now use the config file to do the initial data reduction which will\nthen be used for a ring extraction\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "create the config\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis = Analysis(config)\n\n# for this specific case,w e do not need fine bins in true energy\nanalysis.config.datasets.geom.axes.energy_true = (\n    analysis.config.datasets.geom.axes.energy\n)\n\n# `First get the required observations\nanalysis.get_observations()\n\nprint(analysis.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data extraction\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "analysis.get_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting the ring background\n\nSince the ring background is extracted from real off events, we need to\nuse the wstat statistics in this case. For this, we will use the\n`MapDatasetOnOFF` and the `RingBackgroundMaker` classes.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create exclusion mask\n\nFirst, we need to create an exclusion mask on the known sources. In this\ncase, we need to mask only `MSH 15-52` but this depends on the sources\npresent in our field of view.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# get the geom that we use\ngeom = analysis.datasets[0].counts.geom\nenergy_axis = analysis.datasets[0].counts.geom.axes[\"energy\"]\ngeom_image = geom.to_image().to_cube([energy_axis.squash()])\n\n# Make the exclusion mask\nregions = CircleSkyRegion(center=source_pos, radius=0.3 * u.deg)\nexclusion_mask = ~geom_image.region_mask([regions])\nexclusion_mask.sum_over_axes().plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the present analysis, we use a ring with an inner radius of 0.5 deg\nand width of 0.3 deg.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ring_maker = RingBackgroundMaker(\n    r_in=\"0.5 deg\", width=\"0.3 deg\", exclusion_mask=exclusion_mask\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a stacked dataset\n\nNow, we extract the background for each dataset and then stack the maps\ntogether to create a single stacked map for further analysis\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis_true = analysis.datasets[0].exposure.geom.axes[\"energy_true\"]\nstacked_on_off = MapDatasetOnOff.create(\n    geom=geom_image, energy_axis_true=energy_axis_true, name=\"stacked\"\n)\n\nfor dataset in analysis.datasets:\n    # Ring extracting makes sense only for 2D analysis\n    dataset_on_off = ring_maker.run(dataset.to_image())\n    stacked_on_off.stack(dataset_on_off)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This `stacked_on_off` has `on` and `off` counts and acceptance\nmaps which we will use in all further analysis. The `acceptance` and\n`acceptance_off` maps are the system acceptance of gamma-ray like\nevents in the `on` and `off` regions respectively.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(stacked_on_off)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute correlated significance and correlated excess maps\n\nWe need to convolve our maps with an appropriate smoothing kernel. The\nsignificance is computed according to the Li & Ma expression for ON and\nOFF Poisson measurements, see\n[here](https://ui.adsabs.harvard.edu/abs/1983ApJ...272..317L/abstract)_.\nSince astropy convolution kernels only accept integers, we first convert\nour required size in degrees to int depending on our pixel size.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Using a convolution radius of 0.04 degrees\nestimator = ExcessMapEstimator(0.04 * u.deg, selection_optional=[])\nlima_maps = estimator.run(stacked_on_off)\n\nsignificance_map = lima_maps[\"sqrt_ts\"]\nexcess_map = lima_maps[\"npred_excess\"]\n\n# We can plot the excess and significance maps\nfig, (ax1, ax2) = plt.subplots(\n    figsize=(11, 5), subplot_kw={\"projection\": lima_maps.geom.wcs}, ncols=2\n)\n\nax1.set_title(\"Significance map\")\nsignificance_map.plot(ax=ax1, add_cbar=True)\n\nax2.set_title(\"Excess map\")\nexcess_map.plot(ax=ax2, add_cbar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is often important to look at the signficance distribution outside\nthe exclusion region to check that the background estimation is not\ncontaminated by gamma-ray events. This can be the case when exclusion\nregions are not large enough. Typically, we expect the off distribution\nto be a standard normal distribution.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create a 2D mask for the images\nsignificance_map_off = significance_map * exclusion_mask\nsignificance_all = significance_map.data[np.isfinite(significance_map.data)]\nsignificance_off = significance_map_off.data[np.isfinite(significance_map_off.data)]\n\nfig, ax = plt.subplots()\nax.hist(\n    significance_all,\n    density=True,\n    alpha=0.5,\n    color=\"red\",\n    label=\"all bins\",\n    bins=21,\n)\n\nax.hist(\n    significance_off,\n    density=True,\n    alpha=0.5,\n    color=\"blue\",\n    label=\"off bins\",\n    bins=21,\n)\n\n# Now, fit the off distribution with a Gaussian\nmu, std = norm.fit(significance_off)\nx = np.linspace(-8, 8, 50)\np = norm.pdf(x, mu, std)\nax.plot(x, p, lw=2, color=\"black\")\nax.legend()\nax.set_xlabel(\"Significance\")\nax.set_yscale(\"log\")\nax.set_ylim(1e-5, 1)\nxmin, xmax = np.min(significance_all), np.max(significance_all)\nax.set_xlim(xmin, xmax)\n\nprint(f\"Fit results: mu = {mu:.2f}, std = {std:.2f}\")\nplt.show()\n\n# sphinx_gallery_thumbnail_number = 2"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}