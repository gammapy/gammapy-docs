{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Low level API\n\nIntroduction to Gammapy analysis using the low level API.\n\n## Prerequisites\n\n-  Understanding the gammapy data workflow, in particular what are DL3\n   events and instrument response functions (IRF).\n-  Understanding of the data reduction and modeling fitting process as\n   shown in the analysis with the high level interface\n   tutorial :doc:`/tutorials/starting/analysis_1`\n\n## Context\n\nThis notebook is an introduction to gammapy analysis this time using the\nlower level classes and functions the library. This allows to understand\nwhat happens during two main gammapy analysis steps, data reduction and\nmodeling/fitting.\n\n**Objective: Create a 3D dataset of the Crab using the H.E.S.S. DL3 data\nrelease 1 and perform a simple model fitting of the Crab nebula using\nthe lower level gammapy API.**\n\n## Proposed approach\n\nHere, we have to interact with the data archive (with the\n`~gammapy.data.DataStore`) to retrieve a list of selected observations\n(`~gammapy.data.Observations`). Then, we define the geometry of the\n`~gammapy.datasets.MapDataset` object we want to produce and the maker\nobject that reduce an observation to a dataset.\n\nWe can then proceed with data reduction with a loop over all selected\nobservations to produce datasets in the relevant geometry and stack them\ntogether (i.e.sum them all).\n\nIn practice, we have to:\n\n- Create a `~gammapy.data.DataStore` poiting to the relevant data\n- Apply an observation selection to produce a list of observations,\n  a `~gammapy.data.Observations` object.\n- Define a geometry of the Map we want to produce, with a sky projection\n  and an energy range.\n- Create a `~gammapy.maps.MapAxis` for the energy\n- Create a `~gammapy.maps.WcsGeom` for the geometry\n- Create the necessary makers:\n\n  - the map dataset maker `~gammapy.makers.MapDatasetMaker`\n  - the background normalization maker, here a `~gammapy.makers.FoVBackgroundMaker`\n  - and usually the safe range maker : `~gammapy.makers.SafeMaskMaker`\n\n- Perform the data reduction loop. And for every observation:\n\n  - Apply the makers sequentially to produce the current `~gammapy.datasets.MapDataset`\n  - Stack it on the target one.\n\n- Define the`~gammapy.modeling.models.SkyModel` to apply to the dataset.\n- Create a `~gammapy.modeling.Fit` object and run it to fit the model\n  parameters\n- Apply a `~gammapy.estimators.FluxPointsEstimator` to compute flux points for\n  the spectral part of the fit.\n\n## Setup\n\nFirst, we setup the analysis by performing required imports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nfrom astropy import units as u\nfrom astropy.coordinates import SkyCoord\nfrom regions import CircleSkyRegion\n\n# %matplotlib inline\nimport matplotlib.pyplot as plt\nfrom gammapy.data import DataStore\nfrom gammapy.datasets import MapDataset\nfrom gammapy.estimators import FluxPointsEstimator\nfrom gammapy.makers import FoVBackgroundMaker, MapDatasetMaker, SafeMaskMaker\nfrom gammapy.maps import MapAxis, WcsGeom\nfrom gammapy.modeling import Fit\nfrom gammapy.modeling.models import (\n    FoVBackgroundModel,\n    PointSpatialModel,\n    PowerLawSpectralModel,\n    SkyModel,\n)\nfrom gammapy.utils.check import check_tutorials_setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the datastore and selecting observations\n\nWe first use the `~gammapy.data.DataStore` object to access the\nobservations we want to analyse. Here the H.E.S.S. DL3 DR1.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/hess-dl3-dr1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now define an observation filter to select only the relevant\nobservations. Here we use a cone search which we define with a python\ndict.\n\nWe then filter the `ObservationTable` with\n`~gammapy.data.ObservationTable.select_observations`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "selection = dict(\n    type=\"sky_circle\",\n    frame=\"icrs\",\n    lon=\"83.633 deg\",\n    lat=\"22.014 deg\",\n    radius=\"5 deg\",\n)\nselected_obs_table = data_store.obs_table.select_observations(selection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now retrieve the relevant observations by passing their\n``obs_id`` to the `~gammapy.data.DataStore.get_observations`\nmethod.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations = data_store.get_observations(selected_obs_table[\"OBS_ID\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing reduced datasets geometry\n\nNow we define a reference geometry for our analysis, We choose a WCS\nbased geometry with a binsize of 0.02 deg and also define an energy\naxis:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis = MapAxis.from_energy_bounds(1.0, 10.0, 4, unit=\"TeV\")\n\ngeom = WcsGeom.create(\n    skydir=(83.633, 22.014),\n    binsz=0.02,\n    width=(2, 2),\n    frame=\"icrs\",\n    proj=\"CAR\",\n    axes=[energy_axis],\n)\n\n# Reduced IRFs are defined in true energy (i.e. not measured energy).\nenergy_axis_true = MapAxis.from_energy_bounds(\n    0.5, 20, 10, unit=\"TeV\", name=\"energy_true\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can define the target dataset with this geometry.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stacked = MapDataset.create(\n    geom=geom, energy_axis_true=energy_axis_true, name=\"crab-stacked\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data reduction\n\n### Create the maker classes to be used\n\nThe `~gammapy.makers.MapDatasetMaker` object is initialized as well as\nthe `~gammapy.makers.SafeMaskMaker` that carries here a maximum offset\nselection.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "offset_max = 2.5 * u.deg\nmaker = MapDatasetMaker()\nmaker_safe_mask = SafeMaskMaker(\n    methods=[\"offset-max\", \"aeff-max\"], offset_max=offset_max\n)\n\ncircle = CircleSkyRegion(center=SkyCoord(\"83.63 deg\", \"22.14 deg\"), radius=0.2 * u.deg)\nexclusion_mask = ~geom.region_mask(regions=[circle])\nmaker_fov = FoVBackgroundMaker(method=\"fit\", exclusion_mask=exclusion_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Perform the data reduction loop\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for obs in observations:\n    # First a cutout of the target map is produced\n    cutout = stacked.cutout(\n        obs.pointing_radec, width=2 * offset_max, name=f\"obs-{obs.obs_id}\"\n    )\n    # A MapDataset is filled in this cutout geometry\n    dataset = maker.run(cutout, obs)\n    # The data quality cut is applied\n    dataset = maker_safe_mask.run(dataset, obs)\n    # fit background model\n    dataset = maker_fov.run(dataset)\n    print(\n        f\"Background norm obs {obs.obs_id}: {dataset.background_model.spectral_model.norm.value:.2f}\"\n    )\n    # The resulting dataset cutout is stacked onto the final one\n    stacked.stack(dataset)\n\nprint(stacked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect the reduced dataset\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stacked.counts.sum_over_axes().smooth(0.05 * u.deg).plot(stretch=\"sqrt\", add_cbar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save dataset to disk\n\nIt is common to run the preparation step independent of the likelihood\nfit, because often the preparation of maps, PSF and energy dispersion is\nslow if you have a lot of data. We first create a folder:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = Path(\"analysis_2\")\npath.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then write the maps and IRFs to disk by calling the dedicated\n`~gammapy.datasets.MapDataset.write` method:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filename = path / \"crab-stacked-dataset.fits.gz\"\nstacked.write(filename, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the model\n\nWe first define the model, a `~gammapy.modeling.models.SkyModel`, as the combination of a point\nsource `~gammapy.modeling.models.SpatialModel` with a powerlaw `~gammapy.modeling.models.SpectralModel`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_position = SkyCoord(ra=83.63308, dec=22.01450, unit=\"deg\")\nspatial_model = PointSpatialModel(\n    lon_0=target_position.ra, lat_0=target_position.dec, frame=\"icrs\"\n)\n\nspectral_model = PowerLawSpectralModel(\n    index=2.702,\n    amplitude=4.712e-11 * u.Unit(\"1 / (cm2 s TeV)\"),\n    reference=1 * u.TeV,\n)\n\nsky_model = SkyModel(\n    spatial_model=spatial_model, spectral_model=spectral_model, name=\"crab\"\n)\n\nbkg_model = FoVBackgroundModel(dataset_name=\"crab-stacked\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we assign this model to our reduced dataset:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stacked.models = [sky_model, bkg_model]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit the model\n\nThe `~gammapy.modeling.Fit` class is orchestrating the fit, connecting\nthe ``stats`` method of the dataset to the minimizer. By default, it\nuses ``iminuit``.\n\nIts constructor takes a list of dataset as argument.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fit = Fit(optimize_opts={\"print_level\": 1})\nresult = fit.run([stacked])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `~gammapy.modeling.FitResult` contains information about the optimization and\nparameter error calculation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fitted parameters are visible from the\n`~astropy.modeling.models.Models` object.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(stacked.models.to_parameters_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspecting residuals\n\nFor any fit it is useful to inspect the residual images. We have a few\noptions on the dataset object to handle this. First we can use\n`~gammapy.datasets.MapDataset.plot_residuals_spatial` to plot a residual image, summed over all\nenergies:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stacked.plot_residuals_spatial(method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition, we can also specify a region in the map to show the\nspectral residuals:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "region = CircleSkyRegion(center=SkyCoord(\"83.63 deg\", \"22.14 deg\"), radius=0.5 * u.deg)\n\nstacked.plot_residuals(\n    kwargs_spatial=dict(method=\"diff/sqrt(model)\", vmin=-0.5, vmax=0.5),\n    kwargs_spectral=dict(region=region),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also directly access the ``.residuals()`` to get a map, that we\ncan plot interactively:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "residuals = stacked.residuals(method=\"diff\")\nresiduals.smooth(\"0.08 deg\").plot_interactive(\n    cmap=\"coolwarm\", vmin=-0.2, vmax=0.2, stretch=\"linear\", add_cbar=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the fitted spectrum\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making a butterfly plot\n\nThe `~gammapy.modeling.models.SpectralModel` component can be used to produce a, so-called,\nbutterfly plot showing the envelope of the model taking into account\nparameter uncertainties:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spec = sky_model.spectral_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can actually do the plot using the ``plot_error`` method:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_bounds = [1, 10] * u.TeV\nspec.plot(energy_bounds=energy_bounds, energy_power=2)\nax = spec.plot_error(energy_bounds=energy_bounds, energy_power=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Computing flux points\n\nWe can now compute some flux points using the\n`~gammapy.estimators.FluxPointsEstimator`.\n\nBesides the list of datasets to use, we must provide it the energy\nintervals on which to compute flux points as well as the model component\nname.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_edges = [1, 2, 4, 10] * u.TeV\nfpe = FluxPointsEstimator(energy_edges=energy_edges, source=\"crab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "flux_points = fpe.run(datasets=[stacked])\n\nax = spec.plot_error(energy_bounds=energy_bounds, energy_power=2)\nflux_points.plot(ax=ax, energy_power=2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}