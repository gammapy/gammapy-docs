{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Computing flux upper limits\n\nExplore how to compute flux upper limits for a non-detected source.\n\n## Prerequisites\n\nIt is advisable to understand the general Gammapy modeling and fitting\nframework before proceeding with this notebook, e.g. :doc:`/user-guide/modeling`.\n\n## Context\n\nIn the study of VHE sources, one often encounters no significant\ndetection even after long exposures. In that case, it may be useful to\ncompute flux upper limits (UL) for the said target consistent with the observation.\n\n## Proposed approach\n\nIn this section, we will use an empty observation from the H.E.S.S. DL3 DR1 to understand how\nto quantify non-detections. There are two distinct approaches to consider:\n\n- Test for the presence of emission anywhere in a map and compute an integral flux upper limit at\n  any position (i.e. UL map).\n- Test the presence of emission from a potential source with given position and morphology and compute\n  integral and differential UL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nAs usual, let\u2019s start with some general imports\u2026\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport astropy.units as u\n\nfrom gammapy.datasets import MapDataset, Datasets\nfrom gammapy.estimators import FluxPointsEstimator, ExcessMapEstimator\nfrom gammapy.modeling import select_nested_models\nfrom gammapy.modeling.models import (\n    PointSpatialModel,\n    PowerLawSpectralModel,\n    SkyModel,\n    create_crab_spectral_model,\n)\nfrom gammapy.visualization import plot_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load observation\n\nFor computational purposes, we have\nalready created a `~gammapy.datasets.MapDataset` from observation id ``20275`` from the\npublic H.E.S.S. data release and stored it in ``$GAMMAPY_DATA``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = MapDataset.read(\"$GAMMAPY_DATA/datasets/empty-dl4/empty-dl4.fits.gz\")\ndataset.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Upper Limit maps\n\nWe will first use the `~gammapy.estimators.ExcessMapEstimator` for a quick check to see if\nthere are any potential sources in the field. The ``correlation_radius`` should be around the\nsize of the source you are searching for. You may also use the\n`~gammapy.estimators.TSMapEstimator`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator = ExcessMapEstimator(\n    sum_over_energy_groups=True,\n    selection_optional=\"all\",\n    correlate_off=True,\n    correlation_radius=0.1 * u.deg,\n)\n\nlima_maps = estimator.run(dataset)\n\nsignificance_map = lima_maps[\"sqrt_ts\"]\nexcess_map = lima_maps[\"npred_excess\"]\n\nfig, (ax1, ax2) = plt.subplots(\n    figsize=(11, 4), subplot_kw={\"projection\": lima_maps.geom.wcs}, ncols=2\n)\nax1.set_title(\"Significance map\")\nsignificance_map.plot(ax=ax1, add_cbar=True)\nax2.set_title(\"Excess map\")\nexcess_map.plot(ax=ax2, add_cbar=True)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The significance map looks featureless. We will plot a histogram of the\nsignificance distribution and fit it with a standard normal.\nDeviations from a standard normal can suggest the presence of gamma-ray sources,\nor can also originate from incorrect modeling of the residual hadronic background.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = plt.subplot()\nplot_distribution(\n    significance_map,\n    func=\"norm\",\n    ax=ax,\n    kwargs_hist={\"bins\": 50, \"range\": (-4, 4), \"density\": True},\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also see the correlated upper limits at any position in the map. However, it is important to note\nthat this is **not** a source UL, as the containment correction is not applied here. Instead, it gives the\nflux upper limits contained within the ``correlation_radius`` at each pixel. This can be useful\nwhen making quick look plots to search for the presence of new sources with a field - for example\nin the case of alerts from Gravitational Wave detectors.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lima_maps.flux_ul.plot(add_cbar=True, cmap=\"viridis\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute upper limits for a source\n\nNow, we address a more specific question. Suppose we were expecting a\nsource at a specific position, say the center of our map. Let\u2019s try fitting a point source at that location.\n\nTo ensure the fit converges, we need to constrain the position range.\nFor this, one needs to model (1) only the background (2) model the background + a point source\nand then check the difference in test statistic between the two cases to see if the second model is significantly\npreferred. There is an inbuilt gammapy function, `~gammapy.modeling.select_nested_models` which will do this\ninternally. Case (1) corresponds to the case of source ``amplitude=0``, which we put as our null hypothesis.\nWe freeze the spatial parameters to avoid the fit from converging to other locations. You can alternatively\nconsider constraining the parameter ranges within your expected regions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectral_model = PowerLawSpectralModel()\nspatial_model = PointSpatialModel(frame=\"icrs\")\nspatial_model.lon_0.value = 187.0\nspatial_model.lat_0.value = 2.6\nspatial_model.lat_0.frozen = True\nspatial_model.lon_0.frozen = True\n\n\nsky_model = SkyModel(\n    spatial_model=spatial_model, spectral_model=spectral_model, name=\"test\"\n)\ndataset.models = sky_model\nLLR = select_nested_models(\n    Datasets(dataset), parameters=[sky_model.parameters[\"amplitude\"]], null_values=[0]\n)\nprint(LLR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get the fitted parameters of the spectral model under the alternative hypothesis\n(Case 2):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(LLR[\"fit_results\"].parameters.to_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see that the ``ts ~ 4.7``, thus suggesting that the observed\nfluctuations are not significant above the background. Note that here we have\nonly 1 free parameter, the amplitude, and thus, we can assume the simple conversion\nsignificance = $\\sqrt{ts} \\approx 2.2$.\nNow, we will estimate the differential upper limits of the source.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Differential upper limits\n\nIn the absence of a detection, using the model directly from the fit is meaningless as its features can be\nsimply due to background fluctuations.\nIt is important to **set a reasonable model** on the dataset\nbefore proceeding with the `~gammapy.estimators.FluxPointsEstimator`. This model can come from\nmeasurements from other instruments, be an extrapolation of the flux\nobserved at other wavelengths, come from theoretical estimations, etc.\nIn particular, a model with a negative amplitude as obtained above should not be used.\n\nNote that **the computed upper limits depend on the spectral parameters of the assumed model**.\nHere, we compute the 3-sigma upper limits for assuming a spectral index of 2.0.\nWe also fix the spatial parameters of the model to prevent the minimiser\nfrom wandering off to different regions in the FoV.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model1 = sky_model.copy(name=\"model1\")\nmodel1.parameters[\"amplitude\"].value = 1e-14\nmodel1.parameters[\"index\"].value = 2.0\nmodel1.freeze(model_type=\"spatial\")\n\nenergy_edges = dataset.geoms[\"geom\"].axes[\"energy\"].edges\nfp_est = FluxPointsEstimator(\n    selection_optional=\"all\", energy_edges=energy_edges, n_sigma_ul=3\n)\n\ndataset.models = model1\nfp1 = fp_est.run(dataset)\n\n\nfp1.plot(sed_type=\"dnde\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Integral upper limits\n\nTo compute the integral upper limits between certain energies,\nwe can simply run  `~gammapy.estimators.FluxPointsEstimator`\nwith one bin in energy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "emin = energy_edges[0]\nemax = energy_edges[-1]\nest2 = FluxPointsEstimator(selection_optional=[\"ul\"], energy_edges=[emin, emax])\nfp2 = est2.run(dataset)\nprint(\n    f\"Integral upper limit between ${emin:.1f} and ${emax:.1f} is ${fp2.flux_ul.quantity.ravel()[0]:.2e}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sensitivity estimation\n\nWe can then ask,  **would this source have been detectable given this IRF/exposure time?**\n\nThe `~gammapy.estimators.FluxPointsEstimator` can be used to obtain the sensitivity,\nwhich can be compared to the flux prediction for a given (hypothetical) source. We have the 5-sigma\nsensitivity here, which can be configured using ``n_sigma_sensitivity``\nparameter of this estimator. Let us see what we would have seen if a Crab-like source was\npresent in the center.\nNote that this computed sensitivity does not take into account the factors\nsuch as the minimum number of gamma-rays (see :doc:`/tutorials/analysis-1d/cta_sensitivity`)\nand is dependent on the analysis configuration.\nWe compare this with the known Crab spectrum.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crab_model = create_crab_spectral_model()\n\nfp1.flux_sensitivity.plot(label=\"sensitivity\")\ncrab_model.plot(\n    energy_bounds=fp1.geom.axes[\"energy\"], sed_type=\"flux\", label=\"Crab spectrum\"\n)\nplt.grid(which=\"minor\", alpha=0.3)\n\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thus, a Crab-like source should have been above our sensitivity till around ~ 4 TeV for this specific observation.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}