{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# VERITAS with Gammapy\n\nExplore VERITAS point-like DL3 files, including event lists and IRFs and\ncalculate Li & Ma significance, spectra, and fluxes.\n\n[VERITAS](https://veritas.sao.arizona.edu/)_ (Very Energetic Radiation\nImaging Telescope Array System) is a ground-based gamma-ray instrument\noperating at the Fred Lawrence Whipple Observatory (FLWO) in southern\nArizona, USA. It is an array of four 12m optical reflectors for\ngamma-ray astronomy in the ~ 100 GeV to > 30 TeV energy range.\n\nVERITAS data are private and lower level analysis is done using either\nthe\n[Eventdisplay](https://github.com/VERITAS-Observatory/EventDisplay_v4)_\nor [VEGAS (internal access\nonly)](https://github.com/VERITAS-Observatory/VEGAS)_ analysis\npackages to produce DL3 files (using\n[V2DL3](https://github.com/VERITAS-Observatory/V2DL3)_), which can be\nused in Gammapy to produce high-level analysis products. A small sub-set\nof archival Crab nebula data has been publicly released to accompany\nthis tutorial, which provides an introduction to VERITAS data analysis\nusing gammapy for VERITAS members and external users alike.\n\nThis notebook is only intended for use with these publicly released Crab\nnebula files and the use of other sources or datasets may require\nmodifications to this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimport astropy.units as u\n\nfrom gammapy.maps import MapAxis, WcsGeom, RegionGeom\n\nfrom regions import CircleSkyRegion, PointSkyRegion\nfrom gammapy.data import DataStore\nfrom gammapy.modeling.models import SkyModel, LogParabolaSpectralModel\nfrom gammapy.modeling import Fit\nfrom gammapy.datasets import Datasets, SpectrumDataset\nfrom gammapy.estimators import FluxPointsEstimator, LightCurveEstimator\nfrom gammapy.makers import (\n    ReflectedRegionsBackgroundMaker,\n    SafeMaskMaker,\n    SpectrumDatasetMaker,\n    WobbleRegionsFinder,\n)\nfrom astropy.coordinates import SkyCoord\nfrom gammapy.visualization import plot_spectrum_datasets_off_regions\nfrom gammapy.utils.regions import extract_bright_star_regions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data exploration\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load in files\n\nFirst, we select and load VERITAS observations of the Crab Nebula. These\nfiles are processed with EventDisplay, but VEGAS analysis should be\nidentical apart from the integration region size, which is handled by ``RAD_MAX``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/veritas/crab-point-like-ED\")\ndata_store.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We filter our data by only taking observations within $5^\\circ$\nof the Crab Nebula. Further details on how to filter observations can be\nfound in :doc:`../../user-guide/dl3`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_position = SkyCoord(83.6333, 22.0145, unit=\"deg\")\n\nselected_obs_table = data_store.obs_table.select_sky_circle(target_position, 5 * u.deg)\nobs_ids = selected_obs_table[\"OBS_ID\"]\n\nobservations = data_store.get_observations(obs_id=obs_ids, required_irf=\"point-like\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Peek the first run in the data release\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek the events and their time/energy/spatial distributions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations[0].events.peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek at the IRFs included. You should verify that\nthe IRFs are filled correctly and that there are no values set to zero\nwithin your analysis range. We can also peek at the effective area\n(``aeff``) or energy migration matrices (``edisp``) with the ``peek()``\nmethod.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations[0].peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate counts and significance\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set the energy binning\n\nThe energy axis will determine the bins in which energy is calculated,\nwhile the true energy axis defines the binning of the energy dispersion\nmatrix and the effective area. Generally, the true energy axis should be\nmore finely binned than the energy axis and span a larger range of\nenergies, and the energy axis should be binned to match the needs of\nspectral reconstruction.\n\nNote that if the `~gammapy.makers.SafeMaskMaker` (which we will define\nlater) is set to exclude events below a given percentage of the\neffective area, it will remove the entire bin containing the energy that\ncorresponds to that percentage. Additionally, spectral bins are\ndetermined based on the energy axis and cannot be finer or offset from\nthe energy axis bin edges. See\n`Safe Data Range <safe-data-range>` for more\ninformation on how the safe mask maker works.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis = MapAxis.from_energy_bounds(\"0.05 TeV\", \"100 TeV\", nbin=50)\nenergy_axis_true = MapAxis.from_energy_bounds(\n    \"0.01 TeV\", \"110 TeV\", nbin=200, name=\"energy_true\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an exclusion mask\n\nHere, we create a spatial mask and append exclusion regions for the\nsource region and stars (< 6th magnitude) contained within the ``exclusion_geom``.\nWe define a star exclusion region of 0.3 deg, which should contain bright stars\nwithin the VERITAS optical PSF.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exclusion_geom = WcsGeom.create(\n    skydir=(target_position.ra.value, target_position.dec.value),\n    binsz=0.01,\n    width=(4, 4),\n    frame=\"icrs\",\n    proj=\"CAR\",\n)\n\nsource_exclusion_region = CircleSkyRegion(center=target_position, radius=0.35 * u.deg)\nexclusion_regions = extract_bright_star_regions(exclusion_geom)\nexclusion_regions.append(source_exclusion_region)\n\nexclusion_mask = ~exclusion_geom.region_mask(exclusion_regions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the integration region\n\nPoint-like DL3 files can only be analyzed using the reflected regions\nbackground method and for a pre-determined integration region (which is\nthe $\\sqrt{\\theta^2}$ used in IRF simulations).\n\nThe default values for moderate/medium cuts are determined by the DL3\nfile\u2019s ``RAD_MAX`` keyword. For VERITAS data (ED and VEGAS), ``RAD_MAX``\nis not energy dependent.\n\nNote that full-enclosure files are required to use any non-point-like\nintegration region.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "on_region = PointSkyRegion(target_position)\ngeom = RegionGeom.create(region=on_region, axes=[energy_axis])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## `~gammapy.makers.SafeMaskMaker`\n\nThe `~gammapy.makers.SafeMaskMaker` sets the boundaries of our analysis based on the\nuncertainties contained in the instrument response functions (IRFs).\n\nFor VERITAS point-like analysis (both ED and VEGAS), the following\nmethods are strongly recommended:\n\n* ``offset-max``: Sets the maximum radial offset from the camera center within which we accept events. This is set to the edge of the VERITAS FoV.\n\n* ``edisp-bias``: Removes events which are reconstructed with energies that have $>5\\%$ energy bias.\n\n* ``aeff-max``: Removes events which are reconstructed to $<10\\%$ of the maximum value of the effective area. These are important to remove for spectral analysis, since they have large uncertainties on their reconstructed energies.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "safe_mask_maker = SafeMaskMaker(\n    methods=[\"offset-max\", \"aeff-max\", \"edisp-bias\"],\n    aeff_percent=10,\n    bias_percent=5,\n    offset_max=1.75 * u.deg,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now run the data reduction chain to calculate our ON and OFF\ncounts. To get a significance for the whole energy range (to match VERITAS packages),\nremove the `~gammapy.makers.SafeMaskMaker` from being applied to ``dataset_on_off``.\n\nThe parameters of the reflected background regions can be changed using\nthe `~gammapy.makers.WobbleRegionsFinder`, which is passed as an\nargument to the\n`~gammapy.makers.ReflectedRegionsBackgroundMaker`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_maker = SpectrumDatasetMaker(selection=[\"counts\", \"exposure\", \"edisp\"])\ndataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=energy_axis_true)\n\nregion_finder = WobbleRegionsFinder(n_off_regions=16)\nbkg_maker = ReflectedRegionsBackgroundMaker(\n    exclusion_mask=exclusion_mask, region_finder=region_finder\n)\n\ndatasets = Datasets()\n\nfor obs_id, observation in zip(obs_ids, observations):\n    dataset = dataset_maker.run(dataset_empty.copy(name=str(obs_id)), observation)\n    dataset = safe_mask_maker.run(dataset, observation)\n    dataset_on_off = bkg_maker.run(dataset, observation)\n    datasets.append(dataset_on_off)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The plot below will show your exclusion regions in black and the center of your\nbackground regions with coloured stars. You should check to make sure\nthese regions are sensible and that none of your background regions\noverlap with your exclusion regions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nax = exclusion_mask.plot()\nplot_spectrum_datasets_off_regions(ax=ax, datasets=datasets)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Significance analysis results\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we display the results of the significance analysis.\n``info_table`` can be modified with ``cumulative = False`` to display a\ntable with rows that correspond to the values for each run separately.\n\nHowever, ``cumulative = True`` is needed to produce the combined values\nin the next cell.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "info_table = datasets.info_table(cumulative=True)\nprint(info_table)\n\nprint(f\"ON: {info_table['counts'][-1]}\")\nprint(f\"OFF: {info_table['counts_off'][-1]}\")\nprint(f\"Significance: {info_table['sqrt_ts'][-1]:.2f} sigma\")\nprint(f\"Alpha: {info_table['alpha'][-1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the cumulative excess counts and significance over\ntime. For a steady source, we generally expect excess to increase\nlinearly with time and for significance to increase as\n$\\sqrt{\\textrm{time}}$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, (ax_excess, ax_sqrt_ts) = plt.subplots(figsize=(10, 4), ncols=2, nrows=1)\nax_excess.plot(\n    info_table[\"livetime\"].to(\"h\"),\n    info_table[\"excess\"],\n    marker=\"o\",\n)\n\nax_excess.set_title(\"Excess\")\nax_excess.set_xlabel(\"Livetime [h]\")\nax_excess.set_ylabel(\"Excess events\")\n\nax_sqrt_ts.plot(\n    info_table[\"livetime\"].to(\"h\"),\n    info_table[\"sqrt_ts\"],\n    marker=\"o\",\n)\n\nax_sqrt_ts.set_title(\"Significance\")\nax_sqrt_ts.set_xlabel(\"Livetime [h]\")\nax_sqrt_ts.set_ylabel(\"Significance [sigma]\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make a spectrum\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we\u2019ll calculate the source spectrum. This uses a forward-folding\napproach that will assume a given spectrum and fit the counts calculated\nabove to that spectrum in each energy bin specified by the\n``energy_axis``.\n\nFor this reason, it\u2019s important that spectral model be set as closely as\npossible to the expected spectrum - for the Crab nebula, this is a\n`~gammapy.modeling.models.LogParabolaSpectralModel`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectral_model = LogParabolaSpectralModel(\n    amplitude=3.75e-11 * u.Unit(\"cm-2 s-1 TeV-1\"),\n    alpha=2.45,\n    beta=0.15,\n    reference=1 * u.TeV,\n)\n\nmodel = SkyModel(spectral_model=spectral_model, name=\"crab\")\n\ndatasets.models = [model]\n\nfit_joint = Fit()\nresult_joint = fit_joint.run(datasets=datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best-fit spectral parameters are shown in this table.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(datasets.models.to_parameters_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect how well our data fit the model\u2019s predicted counts in\neach energy bin.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax_spectrum, ax_residuals = datasets[0].plot_fit()\nax_spectrum.set_ylim(0.1, 40)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now calculate flux points to get a spectrum by fitting the\n``result_joint`` model\u2019s amplitude in selected energy bands (defined by\n``energy_edges``). We set ``selection_optional = \"all\"`` in\n`~gammapy.estimators.FluxPointsEstimator`, which will include a calcuation for the upper\nlimits in bins with a significance $< 2\\sigma$.\n\nIn the case of a non-detection or to obtain better upper limits,\nconsider expanding the scan range for the norm parameter in\n`~gammapy.estimators.FluxPointsEstimator`. See\n:doc:`../api/estimators` for more details on how to do this.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fpe = FluxPointsEstimator(\n    energy_edges=np.logspace(-0.7, 1.5, 12) * u.TeV,\n    source=\"crab\",\n    selection_optional=\"all\",\n)\nflux_points = fpe.run(datasets=datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can plot our flux points along with the best-fit spectral model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = flux_points.plot()\nspectral_model.plot(ax=ax, energy_bounds=(0.1, 30) * u.TeV)\nspectral_model.plot_error(ax=ax, energy_bounds=(0.1, 30) * u.TeV)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make a lightcurve and caluclate integral flux\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Integral flux can be calculated by integrating the spectral model we fit\nearlier. This will be a model-dependent flux estimate, so the choice of\nspectral model should match the data as closely as possible.\n\n``e_min`` and ``e_max`` should be adjusted depending on the analysis\nrequirements. Note that the actual energy threshold will use the closest\nbin defined by the ``energy_axis`` binning.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "e_min = 0.25 * u.TeV\ne_max = 30 * u.TeV\n\nflux, flux_errp, flux_errn = result_joint.models[\"crab\"].spectral_model.integral_error(\n    e_min, e_max\n)\nprint(\n    f\"Integral flux > {e_min}: {flux.value:.2} + {flux_errp.value:.2} {flux.unit} - {flux_errn.value:.2} {flux.unit}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we\u2019ll create a run-wise binned light curve. See the\n:doc:`../analysis-time/light_curve_flare` tutorial for instructions on\nhow to set up sub-run binning. Here, we set our energy edges so that the\nlight curve has an energy threshold of 0.25 TeV and will plot upper\nlimits for time bins with significance $<2 \\sigma$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lc_maker = LightCurveEstimator(\n    energy_edges=[0.25, 30] * u.TeV, source=\"crab\", reoptimize=False\n)\nlc_maker.n_sigma_ul = 2\nlc_maker.selection_optional = [\"ul\"]\nlc = lc_maker.run(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can look at our results by printing the light curve as a table (with\neach line corresponding to a light curve bin) and plotting the light\ncurve.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nlc.sqrt_ts_threshold_ul = 2\nlc.plot(ax=ax, axis_name=\"time\", sed_type=\"flux\")\nplt.tight_layout()\n\ntable = lc.to_table(format=\"lightcurve\", sed_type=\"flux\")\nprint(table[\"time_min\", \"time_max\", \"flux\", \"flux_err\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}