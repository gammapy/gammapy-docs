{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MAGIC with Gammapy\n\nExplore the MAGIC IRFs and perform a point like spectral analysis with energy dependent offset cut.\n\n\n## Introduction\n\n[MAGIC](https://magic.mpp.mpg.de/)_ (Major Atmospheric Gamma Imaging\nCherenkov Telescopes) consists of two Imaging Atmospheric Cherenkov telescopes in La Palma, Spain.\nThese 17m diameter telescopes detect gamma-rays from ~ 30 GeV to 100 TeV.\nThe MAGIC public data release contains around 100 hours of data and can be found [here](https://opendata.magic.pic.es/)_.\nThis notebook presents an analysis based on just two runs of the Crab Nebula.\nIt provides an introduction to using the MAGIC DL3 data products, to produce a\n`~gammapy.datasets.SpectrumDatasetOnOff`. Importantly it shows how to perform a data reduction\nwith energy-dependent directional cuts, as described further below.\nFor further information, see [this paper](https://ui.adsabs.harvard.edu/abs/2024JHEAp..44..266A/abstract)_.\n\n## Prerequisites\n\n-  Understanding the basic data reduction performed in the\n   :doc:`/tutorials/analysis-1d/spectral_analysis` tutorial.\n-  understanding the difference between a\n   [point-like](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/index.html)_\n   and a\n   [full-enclosure](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/full_enclosure/index.html)_\n   IRF.\n\n\n## Context\n\nAs described in the :doc:`/tutorials/analysis-1d/spectral_analysis`\ntutorial, the background is estimated from the field of view (FoV) of the observation.\nSince the MAGIC data release does not include a dedicated background IRF, this estimation\nmust be performed directly from the FoV.\nIn particular, the source and background events are counted within a circular\nON region enclosing the source. The background to be subtracted is then estimated\nfrom one or more OFF regions with an expected background rate similar to the one\nin the ON region (i.e. from regions with similar acceptance).\n\n*Full-containment* IRFs have no directional cut applied, when employed\nfor a 1D analysis, it is required to apply a correction to the IRF\naccounting for flux leaking out of the ON region. This correction is\ntypically obtained by integrating the PSF within the ON region.\n\nWhen computing a *point-like* IRFs, a directional cut around the assumed\nsource position is applied to the simulated events. For this IRF type,\nno PSF component is provided. The size of the ON and OFF regions used\nfor the spectrum extraction should then reflect this cut, since a\nresponse computed within a specific region around the source is being\nprovided.\n\nThe directional cut is typically an angular distance from the assumed\nsource position, $\\theta$. The\n[gamma-astro-data-format](https://gamma-astro-data-formats.readthedocs.io/en/latest/)_\nspecifications offer two different ways to store this information:\n\n* if the same $\\theta$ cut is applied at all energies and offsets, a\n  [RAD_MAX](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/#rad-max)_\n  keyword is added to the header of the data units containing IRF components. This\n  should be used to define the size of the ON and OFF regions;\n* in case an energy-dependent (and offset-dependent) $\\theta$ cut is applied, its\n  values are stored in additional ``FITS`` data unit, named\n  [RAD_MAX_2D](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/#rad-max-2d)_.\n\nGammapy provides a class to automatically read these values,\n`~gammapy.irf.RadMax2D`, for both cases (fixed or energy-dependent\n$\\theta$ cut). In this notebook we will focus on how to perform a\nspectral extraction with a point-like IRF with an energy-dependent\n$\\theta$ cut. We remark that in this case a\n`~regions.PointSkyRegion` (and not a `~regions.CircleSkyRegion`)\nshould be used to define the ON region. If a geometry based on a\n`~regions.PointSkyRegion` is fed to the spectra and the background\n`~gammapy.makers.Maker`, the latter will automatically use the values stored in the\n``RAD_MAX`` keyword / table for defining the size of the ON and OFF\nregions.\n\nBeside the definition of the ON region during the data reduction, the\nremaining steps are identical to the other :doc:`/tutorials/analysis-1d/spectral_analysis`\ntutorial, so we will not detail the data reduction steps already\npresented in the other tutorial.\n\n**Objective: perform the data reduction and analysis of 2 Crab Nebula\nobservations of MAGIC and fit the resulting datasets.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nAs usual, we\u2019ll start with some setup \u2026\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\nimport astropy.units as u\nfrom astropy.coordinates import SkyCoord\nfrom regions import PointSkyRegion\n\n# %matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom gammapy.data import DataStore\nfrom gammapy.datasets import Datasets, SpectrumDataset\nfrom gammapy.makers import (\n    ReflectedRegionsBackgroundMaker,\n    SafeMaskMaker,\n    SpectrumDatasetMaker,\n    WobbleRegionsFinder,\n)\nfrom gammapy.maps import Map, MapAxis, RegionGeom\nfrom gammapy.modeling import Fit\nfrom gammapy.modeling.models import (\n    LogParabolaSpectralModel,\n    SkyModel,\n    create_crab_spectral_model,\n)\nfrom gammapy.visualization import plot_spectrum_datasets_off_regions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n\nWe load the two MAGIC observations of the Crab Nebula which contain a\n``RAD_MAX_2D`` table.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/magic/rad_max/data\")\nobservations = data_store.get_observations(required_irf=\"point-like\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can take a look at the MAGIC IRFs:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations[0].peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``rad_max`` attribute, containing the ``RAD_MAX_2D`` table, is\nautomatically loaded in the observation. As we can see from the IRF\ncomponent axes, the table has a single offset value and 28 estimated\nenergy values.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rad_max = observations[\"5029747\"].rad_max\nprint(rad_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the rad max value against the energy:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nrad_max.plot_rad_max_vs_energy(ax=ax)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the ON region\n\nTo use the ``RAD_MAX_2D`` values to define the sizes of the ON and OFF\nregions it is necessary to specify the ON region as\na `~regions.PointSkyRegion`  i.e. we specify only the center of our ON region.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_position = SkyCoord(ra=83.63, dec=22.01, unit=\"deg\", frame=\"icrs\")\non_region = PointSkyRegion(target_position)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run data reduction chain\n\nWe begin by configuring the dataset maker classes.\nFirst, we define the reconstructed and true energy axes:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis = MapAxis.from_energy_bounds(\n    50, 1e5, nbin=5, per_decade=True, unit=\"GeV\", name=\"energy\"\n)\nenergy_axis_true = MapAxis.from_energy_bounds(\n    10, 1e5, nbin=10, per_decade=True, unit=\"GeV\", name=\"energy_true\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a `~gammapy.maps.RegionGeom` by combining the ON region with the\nestimated energy axis of the `~gammapy.datasets.SpectrumDataset` we want to produce.\nThis geometry in used to create the `~gammapy.datasets.SpectrumDataset`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geom = RegionGeom.create(region=on_region, axes=[energy_axis])\n\ndataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=energy_axis_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `~gammapy.makers.SpectrumDatasetMaker` and `~gammapy.makers.ReflectedRegionsBackgroundMaker`\nwill utilise the $\\theta$ values in `~gammapy.data.Observation.rad_max` to define\nthe sizes of the OFF regions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_maker = SpectrumDatasetMaker(\n    containment_correction=False, selection=[\"counts\", \"exposure\", \"edisp\"]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to define the OFF regions it is recommended to use a\n`~gammapy.makers.WobbleRegionsFinder`, that uses fixed positions for\nthe OFF regions. In the different estimated energy bins we will have OFF\nregions centered at the same positions, but with changing size.\n\nThe parameter ``n_off_regions`` specifies the number of OFF regions to be considered.\nIn this case we use 3.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "region_finder = WobbleRegionsFinder(n_off_regions=3)\nbkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the energy threshold specified in the DL3 files for the safe mask:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "safe_mask_masker = SafeMaskMaker(methods=[\"aeff-default\"])\n\ndatasets = Datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a counts map for visualisation later:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "counts = Map.create(skydir=target_position, width=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform the data reduction loop:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for observation in observations:\n    dataset = dataset_maker.run(\n        dataset_empty.copy(name=str(observation.obs_id)), observation\n    )\n    counts.fill_events(observation.events)\n    dataset_on_off = bkg_maker.run(dataset, observation)\n    dataset_on_off = safe_mask_masker.run(dataset_on_off, observation)\n    datasets.append(dataset_on_off)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can plot the off regions and target positions on top of the counts\nmap:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = counts.plot(cmap=\"viridis\")\ngeom.plot_region(ax=ax, kwargs_point={\"color\": \"k\", \"marker\": \"*\"})\nplot_spectrum_datasets_off_regions(ax=ax, datasets=datasets)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit spectrum\n\nWe perform a joint likelihood fit of the two datasets. For this particular datasets\nwe select a fit range between $80\\,{\\rm GeV}$ and $20\\,{\\rm TeV}$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "e_min = 80 * u.GeV\ne_max = 20 * u.TeV\n\nfor dataset in datasets:\n    dataset.mask_fit = dataset.counts.geom.energy_mask(e_min, e_max)\n\nspectral_model = LogParabolaSpectralModel(\n    amplitude=1e-12 * u.Unit(\"cm-2 s-1 TeV-1\"),\n    alpha=2,\n    beta=0.1,\n    reference=1 * u.TeV,\n)\nmodel = SkyModel(spectral_model=spectral_model, name=\"crab\")\n\ndatasets.models = [model]\n\nfit = Fit()\nresult = fit.run(datasets=datasets)\n\n# we make a copy here to compare it later\nbest_fit_model = model.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit quality and model residuals\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access the results dictionary to see if the fit converged:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and check the best-fit parameters\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(datasets.models.to_parameters_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple way to inspect the model residuals is using the function\n`~SpectrumDatasetOnOff.plot_fit()`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax_spectrum, ax_residuals = datasets[0].plot_fit()\nax_spectrum.set_ylim(0.1, 120)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For more ways of assessing fit quality, please refer to the dedicated\n:doc:`/tutorials/details/fitting` tutorial.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare against the literature\n\nLet us compare the spectrum we obtained against a [previous measurement\nby\nMAGIC](https://ui.adsabs.harvard.edu/abs/2015JHEAp...5...30A/abstract)_.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nplot_kwargs = {\n    \"energy_bounds\": [0.08, 20] * u.TeV,\n    \"sed_type\": \"e2dnde\",\n    \"ax\": ax,\n}\nax.yaxis.set_units(u.Unit(\"TeV cm-2 s-1\"))\nax.xaxis.set_units(u.Unit(\"GeV\"))\ncrab_magic_lp = create_crab_spectral_model(\"magic_lp\")\n\nbest_fit_model.spectral_model.plot(\n    ls=\"-\", lw=1.5, color=\"crimson\", label=\"best fit\", **plot_kwargs\n)\nbest_fit_model.spectral_model.plot_error(facecolor=\"crimson\", alpha=0.4, **plot_kwargs)\ncrab_magic_lp.plot(ls=\"--\", lw=1.5, color=\"k\", label=\"MAGIC reference\", **plot_kwargs)\n\nax.legend()\nax.set_ylim([1e-13, 1e-10])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Dataset simulations\n\nA common way to check if a fit is biased is to simulate multiple datasets with\nthe obtained best fit model, and check the distribution of the fitted parameters.\nHere, we show how to perform one such simulation assuming the measured off counts\nprovide a good distribution of the background.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_simulated = datasets.stack_reduce().copy(name=\"simulated_ds\")\nsimulated_model = best_fit_model.copy(name=\"simulated\")\ndataset_simulated.models = simulated_model\ndataset_simulated.fake(\n    npred_background=dataset_simulated.counts_off * dataset_simulated.alpha\n)\ndataset_simulated.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The important thing to note here is that while this samples the on-counts, the off counts are\nnot sampled. If you have multiple measurements of the off counts, they should be used.\nAlternatively, you can try to create a parametric model of the background.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = fit.run(datasets=[dataset_simulated])\nprint(result.models.to_parameters_table())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}