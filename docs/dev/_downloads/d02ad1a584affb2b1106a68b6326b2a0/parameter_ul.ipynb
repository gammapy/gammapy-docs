{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Constraining parameter limits\n\nExplore how to deal with upper limits on parameters.\n\n## Prerequisites\n\nIt is advisable to understand the general Gammapy modelling and fitting framework before proceeding\nwith this notebook, e.g. see :doc:`/user-guide/modeling`.\n\n## Context\n\nEven with significant detection of a source, constraining specific model parameters may remain difficult,\nallowing only for the calculation of confidence intervals.\n\n## Proposed approach\n\nIn this section, we will use 6 observations of the blazar PKS 2155-304, taken in 2008 by\nH.E.S.S, to constrain the curvature in the spectrum.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nAs usual, let\u2019s start with some general imports\u2026\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport astropy.units as u\nfrom gammapy.datasets import SpectrumDatasetOnOff, Datasets\nfrom gammapy.modeling import Fit, select_nested_models\nfrom gammapy.modeling.models import SkyModel, LogParabolaSpectralModel\nfrom gammapy.estimators import FluxPointsEstimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load observation\n\nWe will use a `~gammapy.datasets.SpectrumDatasetOnOff` to see how to constrain\nmodel parameters. This dataset was obtained from H.E.S.S. observation of the blazar PKS 2155-304.\nDetailed modeling of this dataset can be found in the\n:doc:`/tutorials/astrophysics/ebl` notebook.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_onoff = SpectrumDatasetOnOff.read(\n    \"$GAMMAPY_DATA/PKS2155-steady/pks2155-304_steady.fits.gz\"\n)\ndataset_onoff.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit spectrum\n\nWe will investigate the presence of spectral curvature by modeling the\nobserved spectrum using a `~gammapy.modeling.models.LogParabolaSpectralModel`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectral_model = LogParabolaSpectralModel(\n    amplitude=\"5e-12 TeV-1 s-1 cm-2\", alpha=2, beta=0.5, reference=1.0 * u.TeV\n)\n\nmodel_pks = SkyModel(spectral_model, name=\"model_pks\")\ndataset_onoff.models = model_pks\n\nfit = Fit()\nresult_pks = fit.run(dataset_onoff)\nprint(result_pks.models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the parameter ``beta`` (the curvature parameter) is poorly\nconstrained as the errors are very large.\nTherefore, we will perform a likelihood ratio test to evaluate the significance\nof the curvature compared to the null hypothesis of no curvature. In the null\nhypothesis, ``beta=0``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LLR = select_nested_models(\n    datasets=Datasets(dataset_onoff),\n    parameters=[model_pks.parameters[\"beta\"]],\n    null_values=[0],\n)\nprint(LLR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the improvement in the test statistic after including the\ncurvature is only ~0.3, which corresponds to a significance of only 0.5.\n\nWe can safely conclude that the addition of the curvature parameter does\nnot significantly improve the fit. As a result, the function has internally updated\nthe best fit model to the one corresponding to the null hypothesis (i.e. ``beta=0``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset_onoff.models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute parameter asymmetric errors and upper limits\nIn such a case, it can still be useful to be able to constrain\nthe allowed range of the non-significant parameter (e.g.: to rule\nout parameter values, to compare from theoretical predications, etc.).\n\nFirst, we reset the alternative model on the dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_onoff.models = LLR[\"fit_results\"].models\nparameter = dataset_onoff.models.parameters[\"beta\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then compute the asymmetric errors and upper limits on the parameter\nof interest. It is always useful to ensure that the fit the converged by looking at the\n``success`` and ``message`` keywords.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res_1sig = fit.confidence(datasets=dataset_onoff, parameter=parameter, sigma=1)\nprint(res_1sig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can directly use this to compute $n\\sigma$ upper limits on the parameter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res_2sig = fit.confidence(datasets=dataset_onoff, parameter=parameter, sigma=2)\nll_2sigma = parameter.value - res_2sig[\"errn\"]\nul_2sigma = parameter.value + res_2sig[\"errp\"]\n\nprint(f\"2-sigma lower limit on beta is {ll_2sigma:.2f}\")\nprint(f\"2-sigma upper limit on beta is {ul_2sigma:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Likelihood profile\nWe can also compute the likelihood profile of the parameter.\nFirst we define the scan range such that it encompasses more than the 2-sigma parameter limits.\nThen we call `~gammapy.modeling.Fit.stat_profile` :\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameter.scan_n_values = 25\nparameter.scan_min = parameter.value - 2.5 * res_2sig[\"errn\"]\nparameter.scan_max = parameter.value + 2.5 * res_2sig[\"errp\"]\nparameter.interp = \"lin\"\nprofile = fit.stat_profile(datasets=dataset_onoff, parameter=parameter, reoptimize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The resulting `profile` is a dictionary that stores the likelihood value and the fit result\nfor each value of beta.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot everything together\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "values = profile[\"model_pks.spectral.beta_scan\"]\nloglike = profile[\"stat_scan\"]\nax = plt.gca()\nax.plot(values, loglike - np.min(loglike))\nax.set_xlabel(\"Beta\")\nax.set_ylabel(r\"$\\Delta$TS\")\nax.set_title(r\"$\\beta$-parameter likelihood profile\")\nax.fill_betweenx(\n    x1=parameter.value - res_2sig[\"errn\"],\n    x2=parameter.value + res_2sig[\"errp\"],\n    y=[-0.5, 25],\n    alpha=0.3,\n    color=\"pink\",\n    label=\"1-sigma range\",\n)\nax.fill_betweenx(\n    x1=parameter.value - res_1sig[\"errn\"],\n    x2=parameter.value + res_1sig[\"errp\"],\n    y=[-0.5, 25],\n    alpha=0.3,\n    color=\"salmon\",\n    label=\"2-sigma range\",\n)\nax.set_ylim(-0.5, 25)\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Impact of the model choice on the flux upper limits\nThe flux points depends on the underlying model assumption.\nThis can have a non-negligible impact on the flux upper limits in the energy range\nwhere the model is not well constrained as illustrated in the following figure.\nSo quote preferably upper limits from the model which is the most supported by the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energies = dataset_onoff.geoms[\"geom\"].axes[\"energy\"].edges\nfpe = FluxPointsEstimator(energy_edges=energies, n_jobs=4, selection_optional=[\"ul\"])\n\n# Null hypothesis -- no curvature\ndataset_onoff.models = LLR[\"fit_results_null\"].models\nfp_null = fpe.run(dataset_onoff)\n\n# Alternative hypothesis -- with curvature\ndataset_onoff.models = LLR[\"fit_results\"].models\nfp_alt = fpe.run(dataset_onoff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot them together\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = fp_null.plot(sed_type=\"e2dnde\", color=\"blue\")\nLLR[\"fit_results_null\"].models[0].spectral_model.plot(\n    ax=ax,\n    energy_bounds=(energies[0], energies[-1]),\n    sed_type=\"e2dnde\",\n    color=\"blue\",\n    label=\"No curvature\",\n)\nLLR[\"fit_results_null\"].models[0].spectral_model.plot_error(\n    ax=ax,\n    energy_bounds=(energies[0], energies[-1]),\n    sed_type=\"e2dnde\",\n    facecolor=\"blue\",\n    alpha=0.2,\n)\n\n\nfp_alt.plot(ax=ax, sed_type=\"e2dnde\", color=\"red\")\nLLR[\"fit_results\"].models[0].spectral_model.plot(\n    ax=ax,\n    energy_bounds=(energies[0], energies[-1]),\n    sed_type=\"e2dnde\",\n    color=\"red\",\n    label=\"with curvature\",\n)\nLLR[\"fit_results\"].models[0].spectral_model.plot_error(\n    ax=ax,\n    energy_bounds=(energies[0], energies[-1]),\n    sed_type=\"e2dnde\",\n    facecolor=\"red\",\n    alpha=0.2,\n)\n\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This logic can be extended to any spectral or spatial feature. As an\nexercise, try to compute the 95% spatial extent on the MSH 15-52 dataset\nused for the ring background notebook.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}