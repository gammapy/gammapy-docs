{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Spectral analysis with energy-dependent directional cuts\n\nPerform a point like spectral analysis with energy dependent offset cut.\n\n\n## Prerequisites\n\n-  Understanding the basic data reduction performed in the\n   :doc:`/tutorials/analysis-1d/spectral_analysis` tutorial.\n-  understanding the difference between a\n   [point-like](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/index.html)_\n   and a\n   [full-enclosure](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/full_enclosure/index.html)_\n   IRF.\n\n## Context\n\nAs already explained in the :doc:`/tutorials/analysis-1d/spectral_analysis`\ntutorial, the background is estimated fromthe field of view of the observation.\nIn particular, the source and background events are counted within a circular \nON region enclosing the source. The background to be subtracted is then estimated\nfrom one or more OFF regions with an expected background rate similar to the one\nin the ON region (i.e.\u00a0from regions with similar acceptance).\n\n*Full-containment* IRFs have no directional cut applied, when employed\nfor a 1D analysis, it is required to apply a correction to the IRF\naccounting for flux leaking out of the ON region. This correction is\ntypically obtained by integrating the PSF within the ON region.\n\nWhen computing a *point-like* IRFs, a directional cut around the assumed\nsource position is applied to the simulated events. For this IRF type,\nno PSF component is provided. The size of the ON and OFF regions used\nfor the spectrum extraction should then reflect this cut, since a\nresponse computed within a specific region around the source is being\nprovided.\n\nThe directional cut is typically an angular distance from the assumed\nsource position, $\\theta$. The\n[gamma-astro-data-format](https://gamma-astro-data-formats.readthedocs.io/en/latest/)_\nspecifications offer two different ways to store this information: \\* if\nthe same $\\theta$ cut is applied at all energies and offsets, `a\n`RAD_MAX[\nkeyword](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/#rad-max)_\nis added to the header of the data units containing IRF components. This\nshould be used to define the size of the ON and OFF regions; \\* in case\nan energy- (and offset-) dependent $\\theta$ cut is applied, its\nvalues are stored in additional `FITS` data unit, named\n``RAD_MAX_2D[](https://gamma-astro-data-formats.readthedocs.io/en/latest/irfs/point_like/#rad-max-2d)_.\n\n`Gammapy` provides a class to automatically read these values,\n`~gammapy.irf.RadMax2D`, for both cases (fixed or energy-dependent\n$\\theta$ cut). In this notebook we will focus on how to perform a\nspectral extraction with a point-like IRF with an energy-dependent\n$\\theta$ cut. We remark that in this case a\n`~regions.PointSkyRegion` (and not a `~regions.CircleSkyRegion`)\nshould be used to define the ON region. If a geometry based on a\n`~regions.PointSkyRegion` is fed to the spectra and the background\n`Makers`, the latter will automatically use the values stored in the\n`RAD_MAX` keyword / table for defining the size of the ON and OFF\nregions.\n\nBeside the definition of the ON region during the data reduction, the\nremaining steps are identical to the other :doc:`/tutorials/analysis-1d/spectral_analysis`\ntutorial., so we will not detail the data reduction steps already\npresented in the other tutorial.\n\n**Objective: perform the data reduction and analysis of 2 Crab Nebula\nobservations of MAGIC and fit the resulting datasets.**\n\n## Introduction\n\nWe load two MAGIC observations in the\n[gammapy-data](https://github.com/gammapy/gammapy-data)_ containing\nIRF component with a $\\theta$ cut.\n\nWe define the ON region, this time as a `~regions.PointSkyRegion` instead of a\n`CircleSkyRegion`, i.e.\u00a0we specify only the center of our ON region.\nWe create a `RegionGeom` adding to the region the estimated energy\naxis of the `~gammapy.datasets.SpectrumDataset` object we want to\nproduce. The corresponding dataset maker will automatically use the\n$\\theta$ values in `~gammapy.irf.RadMax2D` to set the\nappropriate ON region sizes (based on the offset on the observation and\non the estimated energy binning).\n\nIn order to define the OFF regions it is recommended to use a\n`~gammapy.makers.WobbleRegionsFinder`, that uses fixed positions for\nthe OFF regions. In the different estimated energy bins we will have OFF\nregions centered at the same positions, but with changing size. As for\nthe `~gammapy.makers.SpectrumDatasetMaker`, the `~gammapy.makers.ReflectedRegionsBackgroundMaker` will use the\nvalues in `~gammapy.irf.RadMax2D` to define the sizes of the OFF\nregions.\n\nOnce the datasets with the ON and OFF counts are created, we can perform\na 1D likelihood fit, exactly as illustrated in the previous example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import astropy.units as u\nfrom astropy.coordinates import SkyCoord\nfrom regions import PointSkyRegion\n\n# %matplotlib inline\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nAs usual, we\u2019ll start with some setup \u2026\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\nfrom gammapy.data import DataStore\nfrom gammapy.datasets import Datasets, SpectrumDataset\nfrom gammapy.makers import (\n    ReflectedRegionsBackgroundMaker,\n    SafeMaskMaker,\n    SpectrumDatasetMaker,\n    WobbleRegionsFinder,\n)\nfrom gammapy.maps import Map, MapAxis, RegionGeom\nfrom gammapy.modeling import Fit\nfrom gammapy.modeling.models import (\n    LogParabolaSpectralModel,\n    SkyModel,\n    create_crab_spectral_model,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\nfrom gammapy.visualization import plot_spectrum_datasets_off_regions\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n\nWe load the two MAGIC observations of the Crab Nebula containing the\n`RAD_MAX_2D` table.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/magic/rad_max/data\")\nobservations = data_store.get_observations(required_irf=\"point-like\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A `RadMax2D` attribute, containing the `RAD_MAX_2D` table, is\nautomatically loaded in the observation. As we can see from the IRF\ncomponent axes, the table has a single offset value and 28 estimated\nenergy values.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rad_max = observations[\"5029747\"].rad_max\nprint(rad_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the rad max value against the energy:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nrad_max.plot_rad_max_vs_energy(ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the ON region\n\nTo use the `RAD_MAX_2D` values to define the sizes of the ON and OFF\nregions **it is necessary to specify the ON region as\na `~regions.PointSkyRegion`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_position = SkyCoord(ra=83.63, dec=22.01, unit=\"deg\", frame=\"icrs\")\non_region = PointSkyRegion(target_position)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run data reduction chain\n\nWe begin with the configuration of the dataset maker classes:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# true and estimated energy axes\nenergy_axis = MapAxis.from_energy_bounds(\n    50, 1e5, nbin=5, per_decade=True, unit=\"GeV\", name=\"energy\"\n)\nenergy_axis_true = MapAxis.from_energy_bounds(\n    10, 1e5, nbin=10, per_decade=True, unit=\"GeV\", name=\"energy_true\"\n)\n\n# geometry defining the ON region and SpectrumDataset based on it\ngeom = RegionGeom.create(region=on_region, axes=[energy_axis])\n\ndataset_empty = SpectrumDataset.create(geom=geom, energy_axis_true=energy_axis_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `SpectrumDataset` is now based on a geometry consisting of a\nsingle coordinate and an estimated energy axis. The\n`SpectrumDatasetMaker` and `ReflectedRegionsBackgroundMaker` will\ntake care of producing ON and OFF with the proper sizes, automatically\nadopting the $\\theta$ values in `Observation.rad_max`.\n\nAs explained in the introduction, we use a `WobbleRegionsFinder`, to\ndetermine the OFF positions. The parameter `n_off_positions` specifies\nthe number of OFF regions to be considered.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_maker = SpectrumDatasetMaker(\n    containment_correction=False, selection=[\"counts\", \"exposure\", \"edisp\"]\n)\n\n# tell the background maker to use the WobbleRegionsFinder, let us use 3 off\nregion_finder = WobbleRegionsFinder(n_off_regions=3)\nbkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)\n\n# use the energy threshold specified in the DL3 files\nsafe_mask_masker = SafeMaskMaker(methods=[\"aeff-default\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = Datasets()\n\n# create a counts map for visualisation later...\ncounts = Map.create(skydir=target_position, width=3)\n\nfor observation in observations:\n    dataset = dataset_maker.run(\n        dataset_empty.copy(name=str(observation.obs_id)), observation\n    )\n    counts.fill_events(observation.events)\n    dataset_on_off = bkg_maker.run(dataset, observation)\n    dataset_on_off = safe_mask_masker.run(dataset_on_off, observation)\n    datasets.append(dataset_on_off)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can plot the off regions and target positions on top of the counts\nmap:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nax = counts.plot(cmap=\"viridis\")\ngeom.plot_region(ax=ax, kwargs_point={\"color\": \"k\", \"marker\": \"*\"})\nplot_spectrum_datasets_off_regions(ax=ax, datasets=datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit spectrum\n\n| We perform a joint likelihood fit of the two datasets.\n| For this particular datasets we select a fit range between\n  $80\\,{\\rm GeV}$ and $20\\,{\\rm TeV}$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "e_min = 80 * u.GeV\ne_max = 20 * u.TeV\n\nfor dataset in datasets:\n    dataset.mask_fit = dataset.counts.geom.energy_mask(e_min, e_max)\n\nspectral_model = LogParabolaSpectralModel(\n    amplitude=1e-12 * u.Unit(\"cm-2 s-1 TeV-1\"),\n    alpha=2,\n    beta=0.1,\n    reference=1 * u.TeV,\n)\nmodel = SkyModel(spectral_model=spectral_model, name=\"crab\")\n\ndatasets.models = [model]\n\nfit = Fit()\nresult = fit.run(datasets=datasets)\n\n# we make a copy here to compare it later\nbest_fit_model = model.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit quality and model residuals\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access the results dictionary to see if the fit converged:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and check the best-fit parameters\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(datasets.models.to_parameters_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A simple way to inspect the model residuals is using the function\n`~SpectrumDataset.plot_fit()`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax_spectrum, ax_residuals = datasets[0].plot_fit()\nax_spectrum.set_ylim(0.1, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For more ways of assessing fit quality, please refer to the dedicated\n`modeling and fitting tutorial :doc:`/tutorials/api/fitting` tutorial.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare against the literature\n\nLet us compare the spectrum we obtained against a [previous measurement\nby\nMAGIC](https://ui.adsabs.harvard.edu/abs/2015JHEAp...5...30A/abstract)_.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nplot_kwargs = {\n    \"energy_bounds\": [0.08, 20] * u.TeV,\n    \"sed_type\": \"e2dnde\",\n    \"yunits\": u.Unit(\"TeV cm-2 s-1\"),\n    \"xunits\": u.GeV,\n    \"ax\": ax,\n}\n\ncrab_magic_lp = create_crab_spectral_model(\"magic_lp\")\n\nbest_fit_model.spectral_model.plot(\n    ls=\"-\", lw=1.5, color=\"crimson\", label=\"best fit\", **plot_kwargs\n)\nbest_fit_model.spectral_model.plot_error(facecolor=\"crimson\", alpha=0.4, **plot_kwargs)\ncrab_magic_lp.plot(ls=\"--\", lw=1.5, color=\"k\", label=\"MAGIC reference\", **plot_kwargs)\n\nax.legend()\nax.set_ylim([1e-13, 1e-10])\nplt.show()\n\n# sphinx_gallery_thumbnail_number = 4"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}