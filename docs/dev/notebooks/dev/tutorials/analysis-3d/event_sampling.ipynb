{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Event sampling\n\nLearn to sampling events from a given sky model and IRFs.\n\n## Prerequisites\n\nTo understand how to generate a model and a `~gammapy.datasets.MapDataset` and how to fit\nthe data, please refer to the `~gammapy.modeling.models.SkyModel` and\n:doc:`/tutorials/analysis-3d/simulate_3d` tutorial.\n\n## Context\n\nThis tutorial describes how to sample events from an observation of a\none (or more) gamma-ray source(s). The main aim of the tutorial will be\nto set the minimal configuration needed to deal with the Gammapy\nevent-sampler and how to obtain an output photon event list.\n\nThe core of the event sampling lies into the Gammapy\n`~gammapy.datasets.MapDatasetEventSampler` class, which is based on\nthe inverse cumulative distribution function [(Inverse\nCDF)](https://en.wikipedia.org/wiki/Cumulative_distribution_function#Inverse_distribution_function_(quantile_function))_. \n\nThe `~gammapy.datasets.MapDatasetEventSampler` takes in input a\n`~gammapy.datasets.Dataset` object containing the spectral, spatial\nand temporal properties of the source(s) of interest.\n\nThe `~gammapy.datasets.MapDatasetEventSampler` class evaluates the map\nof predicted counts (`npred`) per bin of the given Sky model, and the\n`npred` map is then used to sample the events. In particular, the\noutput of the event-sampler will be a set of events having information\nabout their true coordinates, true energies and times of arrival.\n\nTo these events, IRF corrections (i.e.\u00a0PSF and energy dispersion) can\nalso further applied in order to obtain reconstructed coordinates and\nenergies of the sampled events.\n\nAt the end of this process, you will obtain an event-list in FITS\nformat.\n\n\n## Objective\n\nDescribe the process of sampling events from a given Sky model and\nobtain an output event-list.\n\n\n## Proposed approach\n\nIn this section, we will show how to define an observation and create\na Dataset object. These are both necessary for the event sampling. Then,\nwe will define the Sky model from which we sample events.\n\nIn this tutorial, we propose examples for sampling events of:\n\n-  [a point-like source](#sampling-the-source-and-background-events)_\n-  [a time variable point-like\n   source](#time-variable-source-using-a-lightcurve)_\n-  [an extended source using a template\n   map](#extended-source-using-a-template)_\n-  [a set of observations](#simulate-multiple-event-lists)_\n\nWe will work with the following functions and classes:\n\n-  `~gammapy.data.Observations`\n-  `~gammapy.datasets.Dataset`\n-  `~gammapy.modeling.models.SkyModel`\n-  `~gammapy.datasets.MapDatasetEventSampler`\n-  `~gammapy.data.EventList`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\nAs usual, let\u2019s start with some general imports\u2026\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport numpy as np\nimport astropy.units as u\nfrom astropy.coordinates import Angle, SkyCoord\nfrom astropy.io import fits\nfrom astropy.time import Time\nfrom regions import CircleSkyRegion\nimport matplotlib.pyplot as plt\n\n# %matplotlib inline\nfrom IPython.display import display\nfrom gammapy.data import DataStore, Observation, observatory_locations\nfrom gammapy.datasets import MapDataset, MapDatasetEventSampler\nfrom gammapy.irf import load_cta_irfs\nfrom gammapy.makers import MapDatasetMaker\nfrom gammapy.maps import Map, MapAxis, WcsGeom\nfrom gammapy.modeling import Fit\nfrom gammapy.modeling.models import (\n    ExpDecayTemporalModel,\n    FoVBackgroundModel,\n    Models,\n    PointSpatialModel,\n    PowerLawNormSpectralModel,\n    PowerLawSpectralModel,\n    SkyModel,\n    TemplateSpatialModel,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define an Observation\n\nYou can firstly create a `~gammapy.data.Observations` object that\ncontains the pointing position, the GTIs and the IRF you want to\nconsider.\n\nHereafter, we chose the IRF of the South configuration used for the CTA\nDC1 and we set the pointing position of the simulated field at the\nGalactic Center. We also fix the exposure time to 1 hr.\n\nLet\u2019s start with some initial settings:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = Path(\"$GAMMAPY_DATA/cta-caldb\")\nirf_filename = \"Prod5-South-20deg-AverageAz-14MSTs37SSTs.180000s-v0.1.fits.gz\"\n\npointing = SkyCoord(0.0, 0.0, frame=\"galactic\", unit=\"deg\")\nlivetime = 1 * u.hr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can create the observation:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "irfs = load_cta_irfs(path / irf_filename)\nlocation = observatory_locations[\"cta_south\"]\n\nobservation = Observation.create(\n    obs_id=1001,\n    pointing=pointing,\n    livetime=livetime,\n    irfs=irfs,\n    location=location,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the MapDataset\n\nLet\u2019s generate the `~gammapy.datasets.Dataset` object (for more info\non `~gammapy.datasets.Dataset` objects, please checkout\n:doc:`/tutorials/api/datasets` tutorial):\nwe define the energy axes (true and reconstruncted), the migration axis\nand the geometry of the observation.\n\n*This is a crucial point for the correct configuration of the event\nsampler. Indeed the spatial and energetic binning should be treaten\ncarefully and\u2026 the finer the better. For this reason, we suggest to\ndefine the energy axes (true and reconstructed) by setting a minimum\nbinning of least 10-20 bins per decade for all the sources of interest.\nThe spatial binning may instead be different from source to source and,\nat first order, it should be adopted a binning significantly smaller\nthan the expected source size.*\n\nFor the examples that will be shown hereafter, we set the geometry of\nthe dataset to a field of view of 2degx2deg and we bin the spatial map\nwith pixels of 0.02 deg.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis = MapAxis.from_energy_bounds(\"0.1 TeV\", \"100 TeV\", nbin=10, per_decade=True)\nenergy_axis_true = MapAxis.from_energy_bounds(\n    \"0.03 TeV\", \"300 TeV\", nbin=20, per_decade=True, name=\"energy_true\"\n)\nmigra_axis = MapAxis.from_bounds(0.5, 2, nbin=150, node_type=\"edges\", name=\"migra\")\n\ngeom = WcsGeom.create(\n    skydir=pointing,\n    width=(2, 2),\n    binsz=0.02,\n    frame=\"galactic\",\n    axes=[energy_axis],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following, the dataset is created by selecting the effective\narea, background model, the PSF and the Edisp from the IRF. The dataset\nthus produced can be saved into a FITS file just using the `write()`\nfunction. We put it into the `evt_sampling` sub-folder:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "empty = MapDataset.create(\n    geom,\n    energy_axis_true=energy_axis_true,\n    migra_axis=migra_axis,\n    name=\"my-dataset\",\n)\nmaker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\ndataset = maker.run(empty, observation)\n\nPath(\"event_sampling\").mkdir(exist_ok=True)\ndataset.write(\"./event_sampling/dataset.fits\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the Sky model: a point-like source\n\nNow let\u2019s define a sky model for a point-like source centered 0.5\ndeg far from the Galactic Center and with a power-law spectrum. We then\nsave the model into a yaml file.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectral_model_pwl = PowerLawSpectralModel(\n    index=2, amplitude=\"1e-12 TeV-1 cm-2 s-1\", reference=\"1 TeV\"\n)\nspatial_model_point = PointSpatialModel(\n    lon_0=\"0 deg\", lat_0=\"0.5 deg\", frame=\"galactic\"\n)\n\nsky_model_pntpwl = SkyModel(\n    spectral_model=spectral_model_pwl,\n    spatial_model=spatial_model_point,\n    name=\"point-pwl\",\n)\n\nbkg_model = FoVBackgroundModel(dataset_name=\"my-dataset\")\n\nmodels = Models([sky_model_pntpwl, bkg_model])\n\nfile_model = \"./event_sampling/point-pwl.yaml\"\nmodels.write(file_model, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling the source and background events\n\nNow, we can finally add the `~gammapy.modeling.models.SkyModel` we\nwant to event-sample to the `~gammapy.datasets.Dataset` container:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.models = models\nprint(dataset.models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next step shows how to sample the events with the\n`~gammapy.datasets.MapDatasetEventSampler` class. The class requests a\nrandom number seed generator (that we set with `random_state=0`), the\n`~gammapy.datasets.Dataset` and the `~gammapy.data.Observations`\nobject. From the latter, the\n`~gammapy.datasets.MapDatasetEventSampler` class takes all the meta\ndata information.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = MapDatasetEventSampler(random_state=0)\nevents = sampler.run(dataset, observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output of the event-sampler is an event list with coordinates,\nenergies (true and reconstructed) and time of arrivals of the source and\nbackground events. `events` is a `~gammapy.data.EventList` object\n(for details see e.g. :doc:`/tutorials/data/cta` tutorial.).\nSource and background events are flagged by the MC_ID identifier (where\n0 is the default identifier for the background).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Source events: {(events.table['MC_ID'] == 1).sum()}\")\nprint(f\"Background events: {(events.table['MC_ID'] == 0).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect the properties of the simulated events as follows:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "events.select_offset([0, 1] * u.deg).peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the `~gammapy.datasets.MapDatasetEventSampler` fills the\nmetadata keyword `OBJECT` in the event list using the first model of\nthe SkyModel object. You can change it with the following commands:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "events.table.meta[\"OBJECT\"] = dataset.models[0].name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s write the event list and its GTI extension to a FITS file. We make\nuse of `fits` library in `astropy`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "primary_hdu = fits.PrimaryHDU()\nhdu_evt = fits.BinTableHDU(events.table)\nhdu_gti = fits.BinTableHDU(dataset.gti.table, name=\"GTI\")\nhdu_all = fits.HDUList([primary_hdu, hdu_evt, hdu_gti])\nhdu_all.writeto(\"./event_sampling/events_0001.fits\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate a skymap\n\nA skymap of the simulated events can be obtained with:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "counts = Map.from_geom(geom)\ncounts.fill_events(events)\nplt.figure()\ncounts.sum_over_axes().plot(add_cbar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit the simulated data\n\nWe can now check the sake of the event sampling by fitting the data.\n We make use of the same\n`~gammapy.modeling.models.Models` adopted for the simulation. Hence,\nwe firstly read the `~gammapy.datasets.Dataset` and the model file,\nand we fill the `~gammapy.datasets.Dataset` with the sampled events.\nWe set the `counts` map to the `dataset`:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models_fit = Models.read(\"./event_sampling/point-pwl.yaml\")\n\ndataset.counts = counts\ndataset.models = models_fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s fit the data and look at the results:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fit = Fit()\nresult = fit.run(dataset)\nprint(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results looks great!\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time variable source using a lightcurve\n\nThe event sampler can also handle temporal variability of the simulated\nsources. In this example, we show how to sample a source characterized\nby an exponential decay, with decay time of 2800 seconds, during the\nobservation.\n\nFirst of all, let\u2019s create a lightcurve:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t0 = 2800 * u.s\nt_ref = Time(\"2000-01-01T00:01:04.184\")\n\ntimes = t_ref + livetime * np.linspace(0, 1, 100)\nexpdecay_model = ExpDecayTemporalModel(t_ref=t_ref.mjd * u.d, t0=t0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "where we defined the time axis starting from the reference time\n`t_ref` up to the requested exposure (`livetime`). The bin size of\nthe time-axis is quite arbitrary but, as above for spatial and energy\nbinnings, the finer the better.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we can create the sky model. Just for the sake of the example,\nlet\u2019s boost the flux of the simulated source of an order of magnitude:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectral_model_pwl.amplitude.value = 2e-11\n\nsky_model_pntpwl = SkyModel(\n    spectral_model=spectral_model_pwl,\n    spatial_model=spatial_model_point,\n    temporal_model=expdecay_model,\n    name=\"point-pwl\",\n)\n\nbkg_model = FoVBackgroundModel(dataset_name=\"my-dataset\")\n\nmodels = Models([sky_model_pntpwl, bkg_model])\n\nfile_model = \"./event_sampling/point-pwl_decay.yaml\"\nmodels.write(file_model, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For simplicity, we use the same dataset defined for the previous\nexample:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.models = models\nprint(dataset.models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now, let\u2019s simulate the variable source:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = MapDatasetEventSampler(random_state=0)\nevents = sampler.run(dataset, observation)\n\nprint(f\"Source events: {(events.table['MC_ID'] == 1).sum()}\")\nprint(f\"Background events: {(events.table['MC_ID'] == 0).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now inspect the properties of the simulated source. To do that,\nwe adopt the `select_region` function that extracts only the events\ninto a given `SkyRegion` of a `~gammapy.data.EventList` object:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "src_position = SkyCoord(0.0, 0.5, frame=\"galactic\", unit=\"deg\")\n\non_region_radius = Angle(\"0.15 deg\")\non_region = CircleSkyRegion(center=src_position, radius=on_region_radius)\n\nsrc_events = events.select_region(on_region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we can have a quick look to the data with the `peek` function:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "src_events.peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the right figure of the bottom panel, it is shown the source\nlightcurve that follows a decay trend as expected.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extended source using a template\n\nThe event sampler can also work with a template model. Here we use the\ninterstellar emission model map of the Fermi 3FHL, which can be found in\nthe GAMMAPY data repository.\n\nWe proceed following the same steps showed above and we finally have a\nlook at the event\u2019s properties:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_model = TemplateSpatialModel.read(\n    \"$GAMMAPY_DATA/fermi-3fhl-gc/gll_iem_v06_gc.fits.gz\", normalize=False\n)\n# we make the model brighter artificially so that it becomes visible over the background\ndiffuse = SkyModel(\n    spectral_model=PowerLawNormSpectralModel(norm=5),\n    spatial_model=template_model,\n    name=\"template-model\",\n)\n\nbkg_model = FoVBackgroundModel(dataset_name=\"my-dataset\")\n\nmodels_diffuse = Models([diffuse, bkg_model])\n\nfile_model = \"./event_sampling/diffuse.yaml\"\nmodels_diffuse.write(file_model, overwrite=True)\n\ndataset.models = models_diffuse\nprint(dataset.models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampler = MapDatasetEventSampler(random_state=0)\nevents = sampler.run(dataset, observation)\n\nevents.select_offset([0, 1] * u.deg).peek()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulate multiple event lists\n\nIn some user case, you may want to sample events from a number of\nobservations. In this section, we show how to simulate a set of event\nlists. For simplicity we consider only one point-like source, observed\nthree times for 1 hr and assuming the same pointing position.\n\nLet\u2019s firstly define the time start and the livetime of each\nobservation:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tstarts = Time(\"2020-01-01 00:00:00\") + [1, 5, 7] * u.hr\nlivetimes = [1, 1, 1] * u.hr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_obs = len(tstarts)\nirf_paths = [path / irf_filename] * n_obs\nevents_paths = []\n\nfor idx, tstart in enumerate(tstarts):\n    irfs = load_cta_irfs(irf_paths[idx])\n    observation = Observation.create(\n        obs_id=idx,\n        pointing=pointing,\n        tstart=tstart,\n        livetime=livetimes[idx],\n        irfs=irfs,\n        location=location,\n    )\n\n    dataset = maker.run(empty, observation)\n    dataset.models = models\n    sampler = MapDatasetEventSampler(random_state=idx)\n    events = sampler.run(dataset, observation)\n\n    path = Path(f\"./event_sampling/events_{idx:04d}.fits\")\n    events_paths.append(path)\n    events.table.write(path, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now load the event list and the corresponding IRFs with\n`DataStore.from_events_files` :\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = Path(\"./event_sampling/\")\nevents_paths = list(path.rglob(\"events*.fits\"))\ndata_store = DataStore.from_events_files(events_paths, irf_paths)\ndisplay(data_store.obs_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then you can create the obervations from the data store and make your own\nanalysis following the instructions in the\n:doc:`/tutorials/starting/analysis_2` tutorial.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "observations = data_store.get_observations()\nobservations[0].peek()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n-  Try to sample events for an extended source (e.g.\u00a0a radial gaussian\n   morphology);\n-  Change the spatial model and the spectrum of the simulated Sky model;\n-  Include a temporal model in the simulation\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}