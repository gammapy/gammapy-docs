{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simulating and fitting a time varying source\n\nSimulate and fit a time decaying light curve of a source using the CTA 1DC response.\n\n## Prerequisites\n\n-  To understand how a single binned simulation works, please refer to\n   :doc:`/tutorials/analysis-1d/spectrum_simulation` tutorial and \n   :doc:`/tutorials/analysis-3d/simulate_3d` tutorial for 1D and 3D simulations\n   respectively.\n-  For details of light curve extraction using gammapy, refer to the two\n   tutorials :doc:`/tutorials/analysis-time/light_curve` and\n   :doc:`/tutorials/analysis-time/light_curve_flare` tutorial.\n\n## Context\n\nFrequently, studies of variable sources (eg: decaying GRB light curves,\nAGN flares, etc) require time variable simulations. For most use cases,\ngenerating an event list is an overkill, and it suffices to use binned\nsimulations using a temporal model.\n\n**Objective: Simulate and fit a time decaying light curve of a source\nwith CTA using the CTA 1DC response**\n\n## Proposed approach\n\nWe will simulate 10 spectral datasets within given time intervals (Good\nTime Intervals) following a given spectral (a power law) and temporal\nprofile (an exponential decay, with a decay time of 6 hr ). These are\nthen analysed using the light curve estimator to obtain flux points.\n\nModelling and fitting of lightcurves can be done either - directly on\nthe output of the `LighCurveEstimator` (at the DL5 level) - fit the\nsimulated datasets (at the DL4 level)\n\nIn summary, necessary steps are:\n\n-  Choose observation parameters including a list of\n   `gammapy.data.GTI`\n-  Define temporal and spectral models from :ref:model-gallery as per\n   science case\n-  Perform the simulation (in 1D or 3D)\n-  Extract the light curve from the reduced dataset as shown\n   in :doc:`/tutorials/analysis-time/light_curve` tutorial.\n-  Optionally, we show here how to fit the simulated datasets using a\n   source model\n\n## Setup\n\nAs usual, we\u2019ll start with some general imports\u2026\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport numpy as np\nimport astropy.units as u\nfrom astropy.coordinates import SkyCoord\nfrom astropy.time import Time\n\n# %matplotlib inline\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n\nlog = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And some gammapy specific imports\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.data import Observation, observatory_locations\nfrom gammapy.datasets import Datasets, FluxPointsDataset, SpectrumDataset\nfrom gammapy.estimators import LightCurveEstimator\nfrom gammapy.irf import load_irf_dict_from_file\nfrom gammapy.makers import SpectrumDatasetMaker\nfrom gammapy.maps import MapAxis, RegionGeom, TimeMapAxis\nfrom gammapy.modeling import Fit\nfrom gammapy.modeling.models import (\n    ExpDecayTemporalModel,\n    PowerLawSpectralModel,\n    SkyModel,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first define our preferred time format:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TimeMapAxis.time_format = \"iso\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulating a light curve\n\nWe will simulate 10 spectra between 300 GeV and 10 TeV using an\n`PowerLawSpectralModel` and a `ExpDecayTemporalModel`. The important\nthing to note here is how to attach a different `GTI` to each dataset.\nSince we use spectrum datasets here, we will use a `RegionGeom`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Loading IRFs\nirfs = load_irf_dict_from_file(\n    \"$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits\"\n)\n\n# Reconstructed and true energy axis\nenergy_axis = MapAxis.from_edges(\n    np.logspace(-0.5, 1.0, 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n)\nenergy_axis_true = MapAxis.from_edges(\n    np.logspace(-1.2, 2.0, 31), unit=\"TeV\", name=\"energy_true\", interp=\"log\"\n)\n\ngeom = RegionGeom.create(\"galactic;circle(0, 0, 0.11)\", axes=[energy_axis])\n\n# Pointing position\npointing = SkyCoord(0.5, 0.5, unit=\"deg\", frame=\"galactic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that observations are usually conducted in Wobble mode, in which\nthe source is not in the center of the camera. This allows to have a\nsymmetrical sky position from which background can be estimated.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the source model: A combination of spectral and temporal model\n\ngti_t0 = Time(\"2020-03-01\")\nspectral_model = PowerLawSpectralModel(\n    index=3, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n)\ntemporal_model = ExpDecayTemporalModel(t0=\"6 h\", t_ref=gti_t0.mjd * u.d)\n\nmodel_simu = SkyModel(\n    spectral_model=spectral_model,\n    temporal_model=temporal_model,\n    name=\"model-simu\",\n)\n\n# Look at the model\ndisplay(model_simu.parameters.to_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, define the start and observation livetime wrt to the reference\ntime, `gti_t0`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_obs = 10\n\ntstart = gti_t0 + [1, 2, 3, 5, 8, 10, 20, 22, 23, 24] * u.h\nlvtm = [55, 25, 26, 40, 40, 50, 40, 52, 43, 47] * u.min"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now perform the simulations\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets = Datasets()\n\nempty = SpectrumDataset.create(\n    geom=geom, energy_axis_true=energy_axis_true, name=\"empty\"\n)\n\nmaker = SpectrumDatasetMaker(selection=[\"exposure\", \"background\", \"edisp\"])\n\n\nfor idx in range(n_obs):\n    obs = Observation.create(\n        pointing=pointing,\n        livetime=lvtm[idx],\n        tstart=tstart[idx],\n        irfs=irfs,\n        reference_time=gti_t0,\n        obs_id=idx,\n        location=observatory_locations[\"cta_south\"],\n    )\n    empty_i = empty.copy(name=f\"dataset-{idx}\")\n    dataset = maker.run(empty_i, obs)\n    dataset.models = model_simu\n    dataset.fake()\n    datasets.append(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reduced datasets have been successfully simulated. Let\u2019s take a\nquick look into our datasets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(datasets.info_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract the lightcurve\n\nThis section uses standard light curve estimation tools for a 1D\nextraction. Only a spectral model needs to be defined in this case.\nSince the estimator returns the integrated flux separately for each time\nbin, the temporal model need not be accounted for at this stage. We\nextract the lightcurve in 3 energy bins.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the model:\nspectral_model = PowerLawSpectralModel(\n    index=3, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n)\nmodel_fit = SkyModel(spectral_model=spectral_model, name=\"model-fit\")\n\n# Attach model to all datasets\ndatasets.models = model_fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lc_maker_1d = LightCurveEstimator(\n    energy_edges=[0.3, 0.6, 1.0, 10] * u.TeV,\n    source=\"model-fit\",\n    selection_optional=[\"ul\"],\n)\nlc_1d = lc_maker_1d.run(datasets)\n\nfig, ax = plt.subplots(\n    figsize=(8, 6),\n    gridspec_kw={\"left\": 0.16, \"bottom\": 0.2, \"top\": 0.98, \"right\": 0.98},\n)\nlc_1d.plot(ax=ax, marker=\"o\", axis_name=\"time\", sed_type=\"flux\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fitting temporal models\n\nWe have the reconstructed lightcurve at this point. Now we want to fit a\nprofile to the obtained light curves, using a joint fitting across the\ndifferent datasets, while simultaneously minimising across the temporal\nmodel parameters as well. The temporal models can be applied\n\n-  directly on the obtained lightcurve\n-  on the simulated datasets\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fitting the obtained light curve\n\nThe fitting will proceed through a joint fit of the flux points. First,\nwe need to obtain a set of `FluxPointDatasets`, one for each time bin\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create the datasets by iterating over the returned lightcurve\ndatasets = Datasets()\n\nfor idx, fp in enumerate(lc_1d.iter_by_axis(axis_name=\"time\")):\n    dataset = FluxPointsDataset(data=fp, name=f\"time-bin-{idx}\")\n    datasets.append(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will fit the amplitude, spectral index and the decay time scale. Note\nthat `t_ref` should be fixed by default for the\n`ExpDecayTemporalModel`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the model:\nspectral_model1 = PowerLawSpectralModel(\n    index=2.0, amplitude=\"1e-12 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n)\ntemporal_model1 = ExpDecayTemporalModel(t0=\"10 h\", t_ref=gti_t0.mjd * u.d)\n\nmodel = SkyModel(\n    spectral_model=spectral_model1,\n    temporal_model=temporal_model1,\n    name=\"model-test\",\n)\n\ndatasets.models = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do a joint fit\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fit = Fit()\nresult = fit.run(datasets=datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let\u2019s plot model and data. We plot only the normalisation of the\ntemporal model in relative units for one particular energy range\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(\n    figsize=(8, 6),\n    gridspec_kw={\"left\": 0.16, \"bottom\": 0.2, \"top\": 0.98, \"right\": 0.98},\n)\nlc_1TeV_10TeV = lc_1d.slice_by_idx({\"energy\": slice(2, 3)})\nlc_1TeV_10TeV.plot(ax=ax, sed_type=\"norm\", axis_name=\"time\")\n\ntime_range = lc_1TeV_10TeV.geom.axes[\"time\"].time_bounds\ntemporal_model1.plot(ax=ax, time_range=time_range, label=\"Best fit model\")\n\nax.set_yscale(\"linear\")\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit the datasets\n\nHere, we apply the models directly to the simulated datasets.\n\nFor modelling and fitting more complex flares, you should attach the\nrelevant model to each group of `datasets`. The parameters of a model\nin a given group of dataset will be tied. For more details on joint\nfitting in Gammapy, see :doc:`/tutorials/analysis-3d/analysis_3d`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the model:\nspectral_model2 = PowerLawSpectralModel(\n    index=2.0, amplitude=\"1e-12 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n)\ntemporal_model2 = ExpDecayTemporalModel(t0=\"10 h\", t_ref=gti_t0.mjd * u.d)\n\nmodel2 = SkyModel(\n    spectral_model=spectral_model2,\n    temporal_model=temporal_model2,\n    name=\"model-test2\",\n)\n\ndisplay(model2.parameters.to_table())\n\ndatasets.models = model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do a joint fit\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fit = Fit()\nresult = fit.run(datasets=datasets)\n\ndisplay(result.parameters.to_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the fitted parameters are consistent between fitting flux\npoints and datasets, and match well with the simulated ones\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n1. Re-do the analysis with `MapDataset` instead of `SpectralDataset`\n2. Model the flare of PKS 2155-304 which you obtained using\n   the :doc:`/tutorials/analysis-time/light_curve_flare` tutorial.\n   Use a combination of a Gaussian and Exponential flare profiles.\n3. Do a joint fitting of the datasets.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}