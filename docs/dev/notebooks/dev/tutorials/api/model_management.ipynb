{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Modelling\n\nMultiple datasets and models interaction in Gammapy.\n\n## Aim\n\nThe main aim of this tutorial is to illustrate model management in\nGammapy, specially how to distribute multiple models across multiple\ndatasets. We also show some convenience functions built in gammapy for\nhandling multiple model components.\n\n**Note: Since gammapy v0.18, the responsibility of model management is\nleft totally upon the user. All models, including background models,\nhave to be explicitly defined.** To keep track of the used models, we\ndefine a global `Models` object (which is a collection of `SkyModel`\nobjects) to which we append and delete models.\n\n## Prerequisites\n\n-  Knowledge of 3D analysis, dataset reduction and fitting see the :doc:`/tutorials/starting/analysis_2`\n   tutorial.\n-  Understanding of gammapy models, see the :doc:`/tutorials/api/models` tutorial.\n-  Analysis of the Galactic Center with Fermi-LAT, shown in the  :doc:`/tutorials/data/fermi_lat` tutorial.\n-  Analysis of the Galactic Center with CTA-DC1 , shown in the  :doc:`/tutorials/analysis-3d/analysis_3d` tutorial.\n\n## Proposed approach\n\nTo show how datasets interact with models, we use two pre-computed\ndatasets on the galactic center, one from Fermi-LAT and the other from\nsimulated CTA (DC1) data. We demonstrate\n\n-  Adding background models for each dataset\n-  Sharing a model between multiple datasets\n\nWe then load models from the Fermi 3FHL catalog to show some convenience\nhandling for multiple `Models` together\n\n-  accessing models from a catalog\n-  selecting models contributing to a given region\n-  adding and removing models\n-  freezing and thawing multiple model parameters together\n-  serialising models\n\nFor computational purposes, we do not perform any fitting in this\nnotebook.\n\n## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from astropy import units as u\nfrom astropy.coordinates import SkyCoord\nfrom regions import CircleSkyRegion\nimport matplotlib.pyplot as plt\n\n# %matplotlib inline\nfrom IPython.display import display\nfrom gammapy.datasets import Datasets, MapDataset\nfrom gammapy.maps import Map\nfrom gammapy.modeling.models import (\n    FoVBackgroundModel,\n    Models,\n    PowerLawNormSpectralModel,\n    SkyModel,\n    TemplateSpatialModel,\n    create_fermi_isotropic_diffuse_model,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read the datasets\n\nFirst, we read some precomputed Fermi and CTA datasets, and create a\n`Datasets` object containing the two.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fermi_dataset = MapDataset.read(\n    \"$GAMMAPY_DATA/fermi-3fhl-gc/fermi-3fhl-gc.fits.gz\", name=\"fermi_dataset\"\n)\ncta_dataset = MapDataset.read(\n    \"$GAMMAPY_DATA/cta-1dc-gc/cta-1dc-gc.fits.gz\", name=\"cta_dataset\"\n)\ndatasets = Datasets([fermi_dataset, cta_dataset])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the counts maps to see the region\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\nax1 = plt.subplot(121, projection=fermi_dataset.counts.geom.wcs)\nax2 = plt.subplot(122, projection=cta_dataset.counts.geom.wcs)\n\n\ndatasets[0].counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n    ax=ax1, stretch=\"sqrt\", add_cbar=True\n)\ndatasets[1].counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n    ax=ax2, stretch=\"sqrt\", add_cbar=True\n)\nax1.set_title(\"Fermi counts\")\nax2.set_title(\"CTA counts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "display(datasets.info_table(cumulative=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that while the datasets have an associated background map, they\ncurrently do not have any associated background model. This will be\nadded in the following section\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assigning background models to datasets\n\nFor any IACT dataset (in this case `cta_dataset`) , we have to create\na `FoVBackgroundModel`. Note that `FoVBackgroundModel` must be\nspecified to one dataset only\n\nFor Fermi-LAT, the background contribution is taken from a diffuse\nisotropic template. To convert this into a gammapy `SkyModel`, use the\nhelper function `create_fermi_isotropic_diffuse_model()`\n\nTo attach a model on a particular dataset it is necessary to specify the\n`datasets_names`. Otherwise, by default, the model will be applied to\nall the datasets in `datasets`\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we must create a global `Models` object which acts as the\ncontainer for all models used in a particular analysis\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models = Models()  # global models object\n\n# Create the FoV background model for CTA data\n\nbkg_model = FoVBackgroundModel(dataset_name=cta_dataset.name)\nmodels.append(bkg_model)  # Add the bkg_model to models()\n\n# Read the fermi isotropic diffuse background model\n\ndiffuse_iso = create_fermi_isotropic_diffuse_model(\n    filename=\"$GAMMAPY_DATA/fermi_3fhl/iso_P8R2_SOURCE_V6_v06.txt\",\n)\ndiffuse_iso.datasets_names = fermi_dataset.name  # specifying the dataset name\n\nmodels.append(diffuse_iso)  # Add the fermi_bkg_model to models()\n\n# Now, add the models to datasets\ndatasets.models = models\n\n# You can see that each dataset lists the correct associated models\nprint(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add a model on multiple datasets\n\nIn this section, we show how to add a model to multiple datasets. For\nthis, we specify a list of `datasets_names` to the model.\nAlternatively, not specifying any `datasets_names` will add it to all\nthe datasets.\n\nFor this example, we use a template model of the galactic diffuse\nemission to be shared between the two datasets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create the diffuse model\ndiffuse_galactic_fermi = Map.read(\"$GAMMAPY_DATA/fermi-3fhl-gc/gll_iem_v06_gc.fits.gz\")\n\ntemplate_diffuse = TemplateSpatialModel(\n    diffuse_galactic_fermi, normalize=False\n)  # the template model in this case is already a full 3D model, it should not be normalised\n\ndiffuse_iem = SkyModel(\n    spectral_model=PowerLawNormSpectralModel(),\n    spatial_model=template_diffuse,\n    name=\"diffuse-iem\",\n    datasets_names=[\n        cta_dataset.name,\n        fermi_dataset.name,\n    ],  # specifying list of dataset names\n)  # A power law spectral correction is applied in this case\n\n# Now, add the diffuse model to the global models list\nmodels.append(diffuse_iem)\n\n# add it to the datasets, and inspect\ndatasets.models = models\nprint(datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `diffuse-iem` model is correctly present on both. Now, you can\nproceed with the fit. For computational purposes, we skip it in this\nnotebook\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fit2 = Fit()\nresult2 = fit2.run(datasets)\nprint(result2.success)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading models from a catalog\n\nWe now load the Fermi 3FHL catalog and demonstrate some convenience\nfunctions. For more details on using Gammapy catalog, see the\n:doc:`/tutorials/api/catalog` tutorial.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.catalog import SourceCatalog3FHL\n\ncatalog = SourceCatalog3FHL()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first choose some relevant models from the catalog and create a new\n`Models` object.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gc_sep = catalog.positions.separation(SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\"))\nmodels_3fhl = [_.sky_model() for k, _ in enumerate(catalog) if gc_sep[k].value < 8]\nmodels_3fhl = Models(models_3fhl)\n\nprint(len(models_3fhl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting models contributing to a given region\n\nWe now use `Models.select_region()` to get a subset of models\ncontributing to a particular region. You can also use\n`Models.select_mask()` to get models lying inside the `True` region\nof a mask map\\`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "region = CircleSkyRegion(\n    center=SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\"), radius=3.0 * u.deg\n)\n\nmodels_selected = models_3fhl.select_region(region)\nprint(len(models_selected))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now want to assign `models_3fhl` to the Fermi dataset, and\n`models_selected` to both the CTA and Fermi datasets. For this, we\nexplicitlty mention the `datasets_names` to the former, and leave it\n`None` (default) for the latter.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for model in models_3fhl:\n    if model not in models_selected:\n        model.datasets_names = fermi_dataset.name\n\n# assign the models to datasets\ndatasets.models = models_3fhl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see the models on a particular dataset, you can simply see\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Fermi dataset models: \", datasets[0].models.names)\nprint(\"\\n CTA dataset models: \", datasets[1].models.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combining two Models\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Models` can be extended simply as as python lists\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models.extend(models_selected)\nprint(len(models))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Selecting models from a list\n\nA `Model` can be selected from a list of `Models` by specifying its\nindex or its name.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = models_3fhl[0]\nprint(model)\n\n# Alternatively\nmodel = models_3fhl[\"3FHL J1731.7-3003\"]\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Models.select` can be used to select all models satisfying a list of\nconditions. To select all models applied on the cta_dataset with the\ncharacters `1748` in the name\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models = models_3fhl.select(datasets_names=cta_dataset.name, name_substring=\"1748\")\nprint(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that `Models.select()` combines the different conditions with an\n`AND` operator. If one needs to combine conditions with a `OR`\noperator, the `Models.selection_mask()` method can generate a boolean\narray that can be used for selection. For ex:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "selection_mask = models_3fhl.selection_mask(\n    name_substring=\"1748\"\n) | models_3fhl.selection_mask(name_substring=\"1731\")\n\nmodels_OR = models_3fhl[selection_mask]\nprint(models_OR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing a model from a dataset\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Any addition or removal of a model must happen through the global models\nobject, which must then be re-applied on the dataset(s). Note that\noperations **cannot** be directly performed on `dataset.models()`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# cta_dataset.models.remove()\n# * this is forbidden *\n\n# Remove the model '3FHL J1744.5-2609'\nmodels_3fhl.remove(\"3FHL J1744.5-2609\")\nlen(models_3fhl)\n\n# After any operation on models, it must be re-applied on the datasets\ndatasets.models = models_3fhl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see the models applied on a dataset, you can simply\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(datasets.models.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting models on a (counts) map\n\nThe spatial regions of `Models` can be plotted on a given geom using\n`Models.plot_regions()`. You can also use `Models.plot_positions()`\nto plot the centers of each model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 5))\nax1 = plt.subplot(121, projection=fermi_dataset.counts.geom.wcs)\nax2 = plt.subplot(122, projection=cta_dataset.counts.geom.wcs)\n\nfor ax, dataset in zip([ax1, ax2], datasets):\n    dataset.counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n        ax=ax, stretch=\"sqrt\", add_cbar=True, cmap=\"afmhot\"\n    )\n    dataset.models.plot_regions(ax=ax, color=\"white\")\n    ax.set_title(dataset.name)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Freezing and unfreezing model parameters\n\nFor a given model, any parameter can be (un)frozen individually.\nAdditionally, `model.freeze` and `model.unfreeze` can be used to\nfreeze and unfreeze all parameters in one go.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = models_3fhl[0]\nprint(model)\n\n# To freeze a single parameter\nmodel.spectral_model.index.frozen = True\nprint(model)  # index is now frozen\n\n# To unfreeze a parameter\nmodel.spectral_model.index.frozen = False\n\n# To freeze all parameters of a model\nmodel.freeze()\nprint(model)\n\n# To unfreeze all parameters (except parameters which must remain frozen)\nmodel.unfreeze()\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only spectral or spatial or temporal components of a model can also be\nfrozen\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To freeze spatial components\nmodel.freeze(\"spatial\")\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check if all the parameters of a model are frozen,\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(model.frozen)  # False because spectral components are not frozen\n\nprint(model.spatial_model.frozen)  # all spatial components are frozen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same operations can be performed on `Models` directly - to perform\non a list of models at once, eg\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "models_selected.freeze()  # freeze all parameters of all models\n\nmodels_selected.unfreeze()  # unfreeze all parameters of all models\n\n# print the free parameters in the models\nprint(models_selected.parameters.free_parameters.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are more functionalities which you can explore. In general, using\n`help()` on any function is a quick and useful way to access the\ndocumentation. For ex, `Models.unfreeze_all` will unfreeze all\nparameters, even those which are fixed by default. To see its usage, you\ncan simply type\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "help(models_selected.unfreeze)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serialising models\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`Models` can be (independently of `Datasets`) written to/ read from\na disk as yaml files. Datasets are always serialised along with their\nassociated models, ie, with yaml and fits files. eg:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# To save only the models\nmodels_3fhl.write(\"3fhl_models.yaml\", overwrite=True)\n\n# To save datasets and models\ndatasets.write(\n    filename=\"datasets-gc.yaml\", filename_models=\"models_gc.yaml\", overwrite=True\n)\n\n# To read only models\nmodels = Models.read(\"3fhl_models.yaml\")\nprint(models)\n\n# To read datasets with models\ndatasets_read = Datasets.read(\"datasets-gc.yaml\", filename_models=\"models_gc.yaml\")\nprint(datasets_read)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}