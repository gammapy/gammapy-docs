{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Priors\n\nLearn how you can include prior knowledge into the fitting by setting\npriors on single parameters.\n\n## Prerequisites\n\n-  Knowledge of spectral analysis to produce 1D spectral datasets, see\n   the :doc:`/tutorials/analysis-1d/spectral_analysis` tutorial.\n-  Knowledge of fitting models to datasets, see\n   :doc:`/tutorials/api/fitting` tutorial\n-  General knowledge of statistics and priors\n\n## Context\n\nGenerally, the set of parameters describing best the data is where the\nfit statistic $2 x log L$ has its global minimum. Depending on\nthe type of background estimation, it is either the Cash fit statistic\nor the WStat (see :doc:`/user-guide/stats/fit_statistics` for more\ndetails).\n\nA prior on the value of some of the parameters can be added to this fit\nstatistic. The prior is again a probability density function of the\nmodel parameters and can take different forms, including Gaussian\ndistributions, uniform distributions, etc. The prior includes\ninformation or knowledge about the dataset or the parameters of the fit.\n\nSetting priors on multiple parameters simultaneously is supported,\nHowever, for now, they should not be correlated.\n\nThe spectral dataset used here contains a simulated power-law source and\nits IRFs are based on HESS data of the Crab Nebula (similar to\n:doc:`/tutorials/api/fitting`). We are simulating the source here, so\nthat we can control the input and check the correctness of the fit\nresults.\n\nThe tutorial addresses three examples:\n\n1. Including prior information about the sources index\n2. Encouraging positive amplitude values\n3. How to add a custom prior class?\n\nIn the first example, the Gaussian prior is used. It is shown how to set\na prior on a model parameter and how it modifies the fit statistics. A\nsource is simulated without statistics and fitted with and without the\npriors. The different fit results are discussed.\n\nFor the second example, 1000 datasets containing a very weak source are\nsimulated. Due to the statistical fluctuations, the amplitude\u2019s best-fit\nvalue is negative for some draws. By setting a uniform prior on the\namplitude, this can be avoided.\n\n## The setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom astropy import units as u\nimport matplotlib.pyplot as plt\nfrom gammapy.datasets import SpectrumDatasetOnOff\nfrom gammapy.modeling import Fit\nfrom gammapy.modeling.models import (\n    GaussianPrior,\n    PowerLawSpectralModel,\n    SkyModel,\n    UniformPrior,\n)\nfrom gammapy.utils.check import check_tutorials_setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model and dataset\n\nFirst, we define the source model, a power-law with an index of\n$2.3$\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pl_spectrum = PowerLawSpectralModel(\n    index=2.3,\n    amplitude=1e-11 / u.cm**2 / u.s / u.TeV,\n)\nmodel = SkyModel(spectral_model=pl_spectrum, name=\"simu-source\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data and background are read from pre-computed ON/OFF datasets of\nHESS observations. For simplicity, we stack them together and transform\nthe dataset to a `~gammapy.datasets.SpectrumDataset`. Then we set the model and create\nan Asimov dataset (dataset without statistics) by setting the counts as\nthe model predictions.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = SpectrumDatasetOnOff.read(\n    \"$GAMMAPY_DATA/joint-crab/spectra/hess/pha_obs23523.fits\"\n)\n\n# Set model and fit range\ne_min = 0.66 * u.TeV\ne_max = 30 * u.TeV\ndataset.mask_fit = dataset.counts.geom.energy_mask(e_min, e_max)\ndataset = dataset.to_spectrum_dataset()\n\ndataset1 = dataset.copy()\ndataset1.models = model.copy(name=\"model\")\ndataset1.counts = dataset1.npred()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Including Prior Information about the Sources Index\n\nThe index was assumed to be $2.3$. However, let us assume you\nhave reasons to believe that the index value of the source is actually\n$2.1$. This can be due to theoretical predictions, other\ninstruments\u2019 results, etc. We can now create a Gaussian distributed\nprior with a minimum at the expected value of $2.1$. The standard\ndeviation of the Gaussian quantifies how much we believe the prior\nknowledge to be true. The smaller the standard deviation, the stronger\nthe constraining ability of the prior. For now, we set it to the\narbitrary value of $0.1$.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# initialising the gaussian prior\ngaussianprior = GaussianPrior(mu=2.1, sigma=0.1)\n# setting the gaussian prior on the index parameter\nmodel_prior = model.copy()\nmodel_prior.parameters[\"index\"].prior = gaussianprior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The value of the prior depends on the value of the index. If the index\nvalue equals the Gaussians mean (here 2.1), the prior is zero. This\nmeans that nothing is added to the cash statistics, and this value is\nfavoured in the fit. If the value of the index deviates from the mean of\n2.1, a prior value > 0 is added to the cash statistics.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For the visualisation, the values are appended to the list; this is not a necessity for the fitting\nprior_stat_sums = []\nwith model_prior.parameters.restore_status():\n    i_scan = np.linspace(1.8, 2.3, 100)\n    for a in i_scan:\n        model_prior.parameters[\"index\"].value = a\n        prior_stat_sums.append(model_prior.parameters.prior_stat_sum())\n\nplt.plot(\n    i_scan,\n    prior_stat_sums,\n    color=\"tab:orange\",\n    linestyle=\"dashed\",\n    label=f\"Gaussian Prior: \\n$\\mu = {gaussianprior.mu.value}$; $\\sigma = {gaussianprior.sigma.value}$\",\n)\nplt.axvline(x=gaussianprior.mu.value, color=\"red\")\n\nplt.xlabel(\"Index Value\")\nplt.ylabel(\"Prior\")\nplt.legend()\nplt.xlim(2.0, 2.2)\nplt.ylim(-0.05, 1.1)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fitting a Dataset with and without the Prior\n\nNow, we copy the dataset consisting of the power-law source and assign\nthe model with the Gaussian prior set on its index to it. Both of the\ndatasets are fitted.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset1.fake()\ndataset1_prior = dataset1.copy()\ndataset1_prior.models = model_prior.copy(name=\"prior-model\")\n\nfit = Fit()\nresults = fit.run(dataset1)\n\nresults_prior = fit.run(dataset1_prior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parameters table will mention the type of prior associated to each model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(results_prior.models.to_parameters_table())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see the details of the priors, eg:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(results_prior.models.parameters[\"index\"].prior)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Likelihood profiles can be computed for both the datasets. Hereby,\nthe likelihood gets computed for different values of the index. For each\nstep the other free parameters are getting reoptimized.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset1.models.parameters[\"index\"].scan_n_values = 20\ndataset1_prior.models.parameters[\"index\"].scan_n_values = 20\n\nscan = fit.stat_profile(datasets=dataset1, parameter=\"index\", reoptimize=True)\n\nscan_prior = fit.stat_profile(\n    datasets=dataset1_prior, parameter=\"index\", reoptimize=True\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we can compare the two Likelihood scans. In the first case, we did\nnot set any prior. This means that only the Cash Statistic itself is\ngetting minimized. The Cash statistics minimum is the actual value of\nthe index we used for the simulation ($2.3$). Therefore, the\nbest-fit value was found to be $2.3$. Note how the error bars\ncorrespond to the $1\\sigma$ error, i.e.\u00a0where the stat sum equals\nthe minimum + 1.\n\nThe plot also shows the prior we set on the index for the second\ndataset. The scan was computed above. If the logarithm of the prior is added to the cash\nstatistics, one ends up with the posterior function. The posterior is\nminimized during the second fit to obtain the maximum a posteriori estimation. Its minimum is between the priors and\nthe cash statistics minimum. The best-fit value is $2.16$. We\nweighed the truth with our prior beliefs and ended up with a compromise\nbetween the values. The uncertainty of the parameter is again where the\nposterior distributions equal its minimum + 1.\n\nThe best-fit index value and uncertainty depend strongly on the standard\ndeviation of the Gaussian prior. You can vary $\\sigma$ and see how\nthe Likelihood profiles and corresponding minima will change.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(scan[\"model.spectral.index_scan\"], scan[\"stat_scan\"], label=\"Cash Statistics\")\nplt.plot(\n    i_scan,\n    np.array(prior_stat_sums) + np.min(scan[\"stat_scan\"]),\n    linestyle=\"dashed\",\n    label=\"Prior\",\n)\nplt.plot(\n    scan_prior[\"prior-model.spectral.index_scan\"],\n    scan_prior[\"stat_scan\"],\n    label=\"Posterior\\n(Cash Stat. + Prior)\",\n)\n\npar = dataset1.models.parameters[\"index\"]\nplt.errorbar(\n    x=par.value,\n    y=np.min(scan[\"stat_scan\"]) + 1,\n    xerr=par.error,\n    fmt=\"x\",\n    markersize=6,\n    capsize=8,\n    color=\"darkblue\",\n    label=\"Best-Fit w/o Prior\",\n)\npar = dataset1_prior.models.parameters[\"index\"]\nplt.errorbar(\n    x=par.value,\n    y=np.min(scan_prior[\"stat_scan\"]) + 1,\n    xerr=par.error,\n    fmt=\"x\",\n    markersize=6,\n    capsize=8,\n    color=\"darkgreen\",\n    label=\"Best-Fit w/ Prior\",\n)\nplt.legend()\n# plt.ylim(31.5,35)\nplt.xlabel(\"Index\")\nplt.ylabel(\"Fit Statistics [arb. unit]\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example shows a critical note on using priors: we were able to\nmanipulate the best-fit index. This can have multiple advantages if one\nwants to include additional information. But it should always be used\ncarefully to not falsify or bias any results!\n\nNote how the $\\Delta$\\ TS of the dataset with the prior set is\nlarger ($-53.91$) than the one without prior ($-55.03$)\nsince the index is not fitted to the underlying true value. If the\nGaussian priors mean were the true value of $2.3$, the index would\nbe fitted correctly, and the $\\Delta$\\ TS values would be the\nsame.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Encouraging Positive Amplitude Values\n\nIn the next example, we want to encourage the amplitude to have\npositive, i.e.\u00a0physical, values. Instead of setting hard bounds, we can\nalso set a uniform prior, which prefers positive values to negatives.\n\nWe set the amplitude of the power-law used to simulate the source to a very\nsmall value. Together with statistical fluctuations, this could result in some\nnegative amplitude best-fit values.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_weak = SkyModel(\n    PowerLawSpectralModel(\n        amplitude=1e-13 / u.cm**2 / u.s / u.TeV,\n    ),\n    name=\"weak-model\",\n)\nmodel_weak_prior = model_weak.copy(name=\"weak-model-prior\")\nuniform = UniformPrior(min=0)\nuniform.weight = 2\nmodel_weak_prior.parameters[\"amplitude\"].prior = uniform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set the minimum value to zero and per default, the maximum value\nis set to positive infinity. Therefore, the uniform prior penalty \nis zero, i.e.\u00a0no influence on the fit at all, if the amplitude value\nis positive and a penalty (the weight) in the form of a prior likelihood\nfor negative values.\nHere, we are setting it to 2. This value is only applied if the\namplitude value goes below zero.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uni_prior_stat_sums = []\nwith model_weak_prior.parameters.restore_status():\n    a_scan = np.linspace(-1, 1, 100)\n    for a in a_scan:\n        model_weak_prior.parameters[\"amplitude\"].value = a\n        uni_prior_stat_sums.append(model_weak_prior.parameters.prior_stat_sum())\n\nplt.plot(\n    a_scan,\n    uni_prior_stat_sums,\n    color=\"tab:orange\",\n    linestyle=\"dashed\",\n    label=f\"Uniform Prior\\n $min={uniform.min.value}$, weight={uniform.weight}\",\n)\nplt.xlabel(\"Amplitude Value [1 / (TeV s cm2)]\")\nplt.ylabel(\"Prior\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fitting Multiple Datasets with and without the Prior\n\nTo showcase how the uniform prior affects the fit results, $100$\ndatasets are created and fitted without and with the prior\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results, results_prior = [], []\nN = 100\ndataset2 = dataset.copy()\nfor n in range(N):\n    # simulating the dataset\n    dataset2.models = model_weak.copy()\n    dataset2.fake()\n\n    dataset2_prior = dataset2.copy()\n    dataset2_prior.models = model_weak_prior.copy()\n    # fitting without the prior\n    fit = Fit()\n    result = fit.optimize(dataset2)\n    results.append(\n        {\n            \"index\": result.parameters[\"index\"].value,\n            \"amplitude\": result.parameters[\"amplitude\"].value,\n        }\n    )\n    # fitting with the prior\n    fit_prior = Fit()\n    result = fit_prior.optimize(dataset2_prior)\n    results_prior.append(\n        {\n            \"index\": result.parameters[\"index\"].value,\n            \"amplitude\": result.parameters[\"amplitude\"].value,\n        }\n    )\n\n\nfig, axs = plt.subplots(1, 2, figsize=(7, 4))\nfor i, parname in enumerate([\"index\", \"amplitude\"]):\n    par = np.array([_[parname] for _ in results])\n    c, bins, _ = axs[i].hist(par, bins=20, alpha=0.5, label=\"Without Prior\")\n    par = np.array([_[parname] for _ in results_prior])\n    axs[i].hist(par, bins=bins, alpha=0.5, color=\"tab:green\", label=\"With Prior\")\n    axs[i].axvline(x=model_weak.parameters[parname].value, color=\"red\")\n    axs[i].set_xlabel(f\"Reconstructed spectral\\n {parname}\")\n    axs[i].legend()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The distribution of the best-fit amplitudes shows how less best-fit\namplitudes have negative values. This also has an effect on the\ndistribution of the best-fit indices. How exactly the distribution\nchanges depends on the weight assigned to the uniform prior. The\nstronger the weight, the less negative amplitudes.\n\nNote that the model parameters uncertainties are, per default, computed\nsymmetrical. This can lead to incorrect\nuncertainties, especially with asymmetrical priors like the previous\nuniform. Calculating the uncertainties from the profile likelihood\nis advised. For more details see the :doc:`/tutorials/api/fitting` tutorial.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementing a custom prior\n\nFor now, only ``GaussianPrior`` and ``UniformPrior`` are implemented.\nTo add a use case specific prior one has to create a prior subclass\ncontaining:\n\n-  a tag and a _type used for the serialization\n-  an instantiation of each PriorParameter with their unit and default values\n-  the evaluate function where the mathematical expression for the prior is defined.\n\nAs an example for a custom prior a Jeffrey prior for a scale parameter is chosen.\nThe only parameter is ``sigma`` and the evaluation method return the squared inverse of ``sigma``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.modeling import PriorParameter\nfrom gammapy.modeling.models import Model, Prior\n\n\nclass MyCustomPrior(Prior):\n    \"\"\"Custom Prior.\n\n\n    Parameters\n    ----------\n    min : float\n        Minimum value.\n        Default is -inf.\n    max : float\n        Maximum value.\n        Default is inf.\n    \"\"\"\n\n    tag = [\"MyCustomPrior\"]\n    sigma = PriorParameter(name=\"sigma\", value=1, unit=\"\")\n    _type = \"prior\"\n\n    @staticmethod\n    def evaluate(value, sigma):\n        \"\"\"Evaluate the custom prior.\"\"\"\n        return value / sigma**2\n\n\n# The custom prior is added to the PRIOR_REGISTRY so that it can be serialised.\n\nfrom gammapy.modeling.models import PRIOR_REGISTRY\n\nPRIOR_REGISTRY.append(MyCustomPrior)\n\n# The custom prior is set on the index of a powerlaw spectral model and is evaluated.\ncustomprior = MyCustomPrior(sigma=0.5)\npwl = PowerLawSpectralModel()\npwl.parameters[\"index\"].prior = customprior\ncustomprior(pwl.parameters[\"index\"])\n\n# The power law spectral model can be written into a dictionary.\n# If a model is read in from this dictionary, the custom prior is still set on the index.\n\nprint(pwl.to_dict())\nmodel_read = Model.from_dict(pwl.to_dict())\nmodel_read.parameters.prior"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}