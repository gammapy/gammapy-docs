{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# HAWC with Gammapy\n\nExplore HAWC event lists and instrument response functions (IRFs), then perform the\ndata reduction steps.\n\n## Introduction\n\n[HAWC](https://www.hawc-observatory.org/)_ is an array of\nwater Cherenkov detectors located in Mexico that detects gamma-rays\nin the range between hundreds of GeV and hundreds of TeV.\nGammapy recently added support of HAWC high level data analysis,\nafter export to the current [open data level 3\nformat](https://gamma-astro-data-formats.readthedocs.io/)_.\n\nThe HAWC data is largely private. However, in 2022, a small\nsub-set of HAWC Pass4 event lists from the Crab nebula region\nwas publicly [released](https://data.hawc-observatory.org/datasets/crab_events_pass4/index.php)_.\nThis dataset is 1 GB in size, so only a subset will be used here as an example.\n\n## Tutorial overview\n\nThis notebook is a quick introduction to HAWC data analysis with Gammapy.\nIt briefly describes the HAWC data and how to access it, and then uses a\nsubset of the data to produce a `~gammapy.datasets.MapDataset`, to show how the\ndata reduction is performed.\n\nThe HAWC data release contains events where the energy is estimated using\ntwo different algorithms, referred to as \"NN\" and \"GP\" (see this\n[paper](https://iopscience.iop.org/article/10.3847/1538-4357/ab2f7d)_\nfor a detailed description). These two event classes are not independent, meaning that\nevents are repeated between the NN and GP datasets. Therefore, these data should never\nbe analysed jointly, and one of the two estimators needs to be chosen before\nproceeding.\n\nOnce the data has been reduced to a `~gammapy.datasets.MapDataset`, there are no differences\nin the way that HAWC data is handled with respect to data from any other\nobservatory, such as H.E.S.S. or CTAO.\n\n\n## HAWC data access and reduction\n\nThis is how to access data and IRFs from the HAWC Crab event data release.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import astropy.units as u\nfrom astropy.coordinates import SkyCoord\nimport matplotlib.pyplot as plt\nfrom gammapy.data import DataStore, HDUIndexTable, ObservationTable\nfrom gammapy.datasets import MapDataset\nfrom gammapy.estimators import ExcessMapEstimator\nfrom gammapy.makers import MapDatasetMaker, SafeMaskMaker\nfrom gammapy.maps import Map, MapAxis, WcsGeom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gammapy.utils.check import check_tutorials_setup\n\ncheck_tutorials_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chose which estimator we will use\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_estimator = \"NN\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A useful way to organize the relevant files are with index tables. The\nobservation index table contains information on each particular observation,\nsuch as the run ID. The HDU index table has a row per\nrelevant file (i.e., events, effective area, psf\u2026) and contains the path\nto said file.\nThe HAWC data is divided into different event types, classified using\nthe fraction of the array that was triggered by an event, a quantity\nusually referred to as \"fHit\". These event types are fully independent,\nmeaning that an event will have a unique event type identifier, which\nis usually a number indicating which fHit bin the event corresponds to.\nFor this reason, a single HAWC observation has several HDU index tables\nassociated to it, one per event type. In each table, there will be\npaths to a distinct event list file and IRFs.\nIn the HAWC event data release, all the HDU tables are saved into\nthe same FITS file, and can be accesses through the choice of the hdu index.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the tables\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = \"$GAMMAPY_DATA/hawc/crab_events_pass4/\"\nhdu_filename = f\"hdu-index-table-{energy_estimator}-Crab.fits.gz\"\nobs_filename = f\"obs-index-table-{energy_estimator}-Crab.fits.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is only one observation table\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs_table = ObservationTable.read(data_path + obs_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The remainder of this tutorial utilises just one fHit value, however,\nfor a regular analysis you should combine all fHit bins. Here,\nwe utilise fHit bin number 6. We start by reading the HDU index table\nof this fHit bin\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fHit = 6\nhdu_table = HDUIndexTable.read(data_path + hdu_filename, hdu=fHit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the tables, we can create a `~gammapy.data.DataStore`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_store = DataStore(hdu_table=hdu_table, obs_table=obs_table)\n\ndata_store.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is only one observation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs = data_store.get_observations()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek events from this observation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs.events.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek the energy dispersion:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs.edisp.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek the psf:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obs.psf.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek the background for one transit:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nobs.bkg.reduce_over_axes().plot(add_cbar=True)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Peek the effective exposure for one transit:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure()\nobs.aeff.reduce_over_axes().plot(add_cbar=True)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data reduction into a MapDataset\n\nWe will now produce a `~gammapy.datasets.MapDataset` using the data from one of the\nfHit bins. In order to use all bins, one just needs to repeat this\nprocess inside a for loop that modifies the variable fHit.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we define the geometry and axes, starting with the energy reco axis:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis = MapAxis.from_edges(\n    [1.00, 1.78, 3.16, 5.62, 10.0, 17.8, 31.6, 56.2, 100, 177, 316] * u.TeV,\n    name=\"energy\",\n    interp=\"log\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: this axis is the one used to create the background model map. If\ndifferent edges are used, the `~gammapy.makers.MapDatasetMaker` will interpolate between\nthem, which might lead to unexpected behaviour.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the energy true axis:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "energy_axis_true = MapAxis.from_energy_bounds(\n    1e-3, 1e4, nbin=140, unit=\"TeV\", name=\"energy_true\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, create a geometry around the Crab location:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geom = WcsGeom.create(\n    skydir=SkyCoord(ra=83.63, dec=22.01, unit=\"deg\", frame=\"icrs\"),\n    width=6 * u.deg,\n    axes=[energy_axis],\n    binsz=0.05,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the makers we will use:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "maker = MapDatasetMaker(selection=[\"counts\", \"background\", \"exposure\", \"edisp\", \"psf\"])\nsafe_mask_maker = SafeMaskMaker(methods=[\"aeff-max\"], aeff_percent=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an empty `~gammapy.datasets.MapDataset`.\nThe keyword ``reco_psf=True`` is needed because the HAWC PSF is\nderived in reconstructed energy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_empty = MapDataset.create(\n    geom, energy_axis_true=energy_axis_true, name=f\"fHit {fHit}\", reco_psf=True\n)\ndataset = maker.run(dataset_empty, obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The livetime information is used by the `~gammapy.makers.SafeMaskMaker` to retrieve the\neffective area from the exposure. The HAWC effective area is computed\nfor one source transit above 45\u00ba zenith, which is around 6h.\nSince the effective area condition used here is relative to\nthe maximum, this value does not actually impact the result.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.exposure.meta[\"livetime\"] = \"6 h\"\ndataset = safe_mask_maker.run(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have a dataset that has background and exposure quantities for\none single transit, but our dataset might comprise more. The number\nof transits can be derived using the good time intervals (GTI) stored\nwith the event list. For convenience, the HAWC data release already\nincluded this quantity as a map.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transit_map = Map.read(data_path + \"irfs/TransitsMap_Crab.fits.gz\")\ntransit_number = transit_map.get_by_coord(geom.center_skydir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correct the background and exposure quantities:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.background.data *= transit_number\ndataset.exposure.data *= transit_number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check the dataset we produced\n\nWe will now check the contents of the dataset.\nWe can use the ``.peek()`` method to quickly get a glimpse of the contents\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.peek()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create significance maps to check that the Crab is visible:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "excess_estimator = ExcessMapEstimator(\n    correlation_radius=\"0.2 deg\", selection_optional=[], energy_edges=energy_axis.edges\n)\nexcess = excess_estimator.run(dataset)\n\n(dataset.mask * excess[\"sqrt_ts\"]).plot_grid(\n    add_cbar=True, cmap=\"coolwarm\", vmin=-5, vmax=5\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combining all energies\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "excess_estimator_integrated = ExcessMapEstimator(\n    correlation_radius=\"0.2 deg\", selection_optional=[]\n)\nexcess_integrated = excess_estimator_integrated.run(dataset)\n\nexcess_integrated[\"sqrt_ts\"].plot(add_cbar=True)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n\n-  Repeat the process for a different fHit bin.\n-  Repeat the process for all the fHit bins provided in the data\n   release and fit a model to the result.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n\nNow you know how to access and work with HAWC data. All other\ntutorials and documentation concerning 3D analysis techniques and\nthe `~gammapy.datasets.MapDataset` object can be used from this step on.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}